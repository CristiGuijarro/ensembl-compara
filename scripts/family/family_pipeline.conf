# This is an experimental configuration file for family pipeline

my $release = '57plus';

    # code directories:
my $cvs_root_dir   = '/nfs/team71/analysis/lg4/work';
my $sec_root_dir   = '/software/ensembl/compara';
my $blast_root_dir = $sec_root_dir . '/blast-2.2.22';
my $mafft_root_dir = $sec_root_dir . '/mafft-6.522';

    # data directories:
my $main_pipe_dir   = "/nfs/team71/analysis/lg4/family_${release}";
my $lustre_pipe_dir = "/lustre/scratch103/ensembl/lg4/family_${release}";
my $blastdb_name    = "metazoa_${release}.pep";

    # family database connection parameters (our main database):
my $pipeline_db = {
    -host   => 'compara2',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    -dbname => "lg4_compara_family_${release}",
};

    # homology database connection parameters (we inherit half of the members and sequences from there):
my $homology_db  = {
    -host   => 'compara3',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    # -dbname => "avilella_compara_homology_${release}",
    #
    -dbname => 'avilella_compara_homology_57f',
};

sub hash_2_mysql_params {
    my ($db_conn, $with_db) = @_;

    return "--host=$db_conn->{-host} --port=$db_conn->{-port} "
          ."--user=$db_conn->{-user} --pass=$db_conn->{-pass} "
          .($with_db ? $db_conn->{-dbname} : '');
}

{
        # pass connection parameters into the pipeline initialization script to create adaptors:
    -pipeline_db => $pipeline_db,

        # shell commands that create and pre-fill the pipeline database:
    -pipeline_create_commands => [
        'mysql '.hash_2_mysql_params($pipeline_db, 0)." -e 'CREATE DATABASE $pipeline_db->{-dbname}'",

        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-hive/sql/tables.sql",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-compara/sql/table.sql",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-compara/sql/pipeline-tables.sql",

        'mysqldump '.hash_2_mysql_params($homology_db, 1)
                 #   .' -t member sequence ncbi_taxa_name ncbi_taxa_node method_link genome_db species_set method_link_species_set '
                    .' -t method_link genome_db species_set method_link_species_set '
                    .'| mysql '.hash_2_mysql_params($pipeline_db, 1),

        'mysql '.hash_2_mysql_params($pipeline_db, 1)." -e 'ALTER TABLE member        ENGINE=InnoDB, AUTO_INCREMENT=100000000'",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." -e 'ALTER TABLE sequence      ENGINE=InnoDB, AUTO_INCREMENT=100000000'",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." -e 'ALTER TABLE family_member ENGINE=InnoDB'",

        "mkdir -p $main_pipe_dir",
        "mkdir -p $lustre_pipe_dir",
    ],

    -pipeline_analyses => [
        {   -logic_name => 'load_uniprot_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'module'        => 'Bio::EnsEMBL::Compara::RunnableDB::LoadUniProt',
                'logic_name'    => 'load_uniprot',
                'parameters'    => {},
                'inputlist'     => ['FUN','HUM','MAM','ROD','VRT','INV'],
                'numeric'       =>  0,
                'hive_capacity' => 20,
            },
            -input_ids => [
                { 'input_id' => { 'srs' => 'SWISSPROT', 'tax_div' => '$RangeStart' } },
                { 'input_id' => { 'srs' => 'SPTREMBL',  'tax_div' => '$RangeStart' } },
            ],
        },

        # (the previous analysis will create 'load_uniprot' analysis & 12 jobs)
        
        {   -logic_name => 'dump_member_proteins',
            -module     => 'Bio::EnsEMBL::Compara::RunnableDB::DumpMemberSequencesIntoFasta',
            -parameters => {
                'source_names' => [ 'ENSEMBLPEP','Uniprot/SWISSPROT','Uniprot/SPTREMBL' ],
                'idprefixed' => 1,
            },
            -input_ids => [
                { 'fasta_name' => $blastdb_name },
            ],
            -wait_for  => [ 'load_uniprot_factory', 'load_uniprot' ],
            -blocked   => 1,  # cannot properly wait_for 'load_uniprot' since it doesn't exist yet, so have to block
        },

        {   -logic_name => 'format_blastdb',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids => [
                { 'cmd' => "/software/ensembl/compara/ncbi-blast-2.2.22+/bin/makeblastdb -dbtype prot -logfile ${main_pipe_dir}/makeblastdb.log -in ${main_pipe_dir}/${blastdb_name}", },
            ],
            -wait_for => [ 'dump_member_proteins' ],
        },

        {   -logic_name => 'copy_blastdb_over',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids => [
                { 'cmd' => "cp ${main_pipe_dir}/${blastdb_name}* ${lustre_pipe_dir}", },
            ],
            -wait_for => [ 'format_blastdb' ],
        },

        {   -logic_name => 'family_blast_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'module' => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyBlast',
                'logic_name' => 'family_blast',
                'parameters' => {
                    'inputquery' => 'SELECT DISTINCT s.sequence_id FROM member m, sequence s WHERE m.sequence_id=s.sequence_id AND m.source_name IN ("Uniprot/SPTREMBL", "Uniprot/SWISSPROT", "ENSEMBLPEP") ',
                    'fastadb'    => "${lustre_pipe_dir}/${blastdb_name}",
                    'idprefixed' => 1,
                    'step'       => 100,
                },
                'numeric' => 1,
                'hive_capacity' => 1000,
            },
            -input_ids => [
                {   'input_id' => { 'sequence_id' => '$RangeStart', 'minibatch' => '$RangeCount' }, },
            ],
            -wait_for => [ 'copy_blastdb_over' ],
        },

        # (the previous analysis will create 'family_blast' analysis & jobs)

    ],
};

__END__


        {   -logic_name => 'dump_matrix_to_mcxload',
            -module     => 'SystemCmd',
            -parameters => {
            },
            -input_ids  => [
            ],
            -wait_for   => [ 'family_blast_factory', 'family_blast' ],
            -blocked    => 1,  # cannot properly wait_for 'family_blast' since it doesn't exist yet, so have to block
        },

        {   -logic_name => 'mcl',
            -module     => '',
            -parameters => {
            },
            -input_ids => [
            ],
        },

        {   -logic_name => 'parse_mcl',
            -module     => 'SystemCmd',
            -parameters => {
            },
            -input_ids => [
            ],
        },

        {   -logic_name => 'family_mafft_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'module' => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyMafft',
                'logic_name' => 'family_mafft',
                'inputquery' => 'SELECT family_id FROM family_member GROUP BY family_id HAVING count(*)>1',
                'randomize' => 1,
                'numeric' => 1,
                'hive_capacity' => 400,
                'batch_size' => 10,
            },
            -input_ids => [
                { 'input_id' => { 'family_id' => '$RangeStart' } },
            ],
        },
        
        # (the previous analysis will create 'family_mafft' analysis & jobs)
        
        # ToDo: paragraphs 12 and 13

        {   -logic_name => '',
            -module     => '',
            -parameters => {
            },
            -input_ids => [
            ],
        },

    ],

};

