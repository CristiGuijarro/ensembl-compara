## Configuration file for the MCL family pipeline (development in progress)
#
## Run it like this:
#
# time init_pipeline.pl -conf family_pipeline.conf
# 
# rel.57    <6min

my $release = '57plus';

    # code directories:
my $cvs_root_dir   = $ENV{'HOME'}.'/work';
#my $cvs_root_dir   = $ENV{'HOME'}.'/ensembl_main'; ## for some Compara developers

my $sec_root_dir      = '/software/ensembl/compara';
my $mafft_root_dir    = $sec_root_dir . '/mafft-6.522';

my $blastplus_bin_dir = $sec_root_dir . '/ncbi-blast-2.2.22+/bin';
my $mcl_bin_dir       = $sec_root_dir . '/mcl-09-308/bin';
    
    # data directories:
my $main_pipe_dir   = $ENV{'HOME'}."/family_${release}";
my $lustre_pipe_dir = '/lustre/scratch103/ensembl/'.$ENV{'USER'}."/family_${release}";
my $blastdb_name    = "metazoa_${release}.pep";
my $tcx_name        = "family_${release}.tcx";
my $itab_name       = "family_${release}.itab";
my $mcl_name        = "family_${release}.mcl";

    # family database connection parameters (our main database):
my $pipeline_db = {
    -host   => 'compara2',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    -dbname => "lg4_compara_family_${release}",
};

    # homology database connection parameters (we inherit half of the members and sequences from there):
my $homology_db  = {
    -host   => 'compara3',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    # -dbname => "avilella_compara_homology_${release}",
    #
    -dbname => 'avilella_compara_homology_57f',
};

sub hash_2_mysql_params {
    my ($db_conn, $with_db) = @_;

    return "--host=$db_conn->{-host} --port=$db_conn->{-port} "
          ."--user=$db_conn->{-user} --pass=$db_conn->{-pass} "
          .($with_db ? $db_conn->{-dbname} : '');
}

{
        # pass connection parameters into the pipeline initialization script to create adaptors:
    -pipeline_db => $pipeline_db,

        # shell commands that create and pre-fill the pipeline database:
    -pipeline_create_commands => [
        'mysql '.hash_2_mysql_params($pipeline_db, 0)." -e 'CREATE DATABASE $pipeline_db->{-dbname}'",

        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-hive/sql/tables.sql",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-hive/sql/procedures.sql",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-compara/sql/table.sql",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." <$cvs_root_dir/ensembl-compara/sql/pipeline-tables.sql",

        'mysqldump '.hash_2_mysql_params($homology_db, 1)
                    .' -t ncbi_taxa_name ncbi_taxa_node method_link genome_db species_set method_link_species_set '
#                    .' -t method_link genome_db species_set method_link_species_set '
                    .'| mysql '.hash_2_mysql_params($pipeline_db, 1),

        'mysqldump '.hash_2_mysql_params($homology_db, 1)
                    .' -t member sequence family family_member | sed "s/ENGINE=MyISAM/ENGINE=InnoDB/" '
                    .'| mysql '.hash_2_mysql_params($pipeline_db, 1),

        'mysql '.hash_2_mysql_params($pipeline_db, 1)." -e 'ALTER TABLE member   AUTO_INCREMENT=100000000'",
        'mysql '.hash_2_mysql_params($pipeline_db, 1)." -e 'ALTER TABLE sequence AUTO_INCREMENT=100000000'",

        "mkdir -p $main_pipe_dir",
        "mkdir -p $lustre_pipe_dir",
    ],

    -pipeline_analyses => [
        {   -logic_name => 'load_uniprot_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'logic_name'    => 'load_uniprot',
                'inputlist'     => ['FUN','HUM','MAM','ROD','VRT','INV'],
                'numeric'       =>  0,
            },
            -input_ids => [
                { 'input_id' => { 'srs' => 'SWISSPROT', 'tax_div' => '$RangeStart' } },
                { 'input_id' => { 'srs' => 'SPTREMBL',  'tax_div' => '$RangeStart' } },
            ],
        },

            # NB: jobs will be created by the JobFactory above
        {   -logic_name    => 'load_uniprot',
            -module        => 'Bio::EnsEMBL::Compara::RunnableDB::LoadUniProt',
            -parameters    => {},
            -hive_capacity => 20,
            -input_ids     => [
            ],
            -wait_for  => [ 'load_uniprot_factory' ],
        },
        
        {   -logic_name => 'dump_member_proteins',
            -module     => 'Bio::EnsEMBL::Compara::RunnableDB::DumpMemberSequencesIntoFasta',
            -parameters => {
                'source_names' => [ 'ENSEMBLPEP','Uniprot/SWISSPROT','Uniprot/SPTREMBL' ],
                'idprefixed' => 1,
            },
            -input_ids => [
                { 'fasta_name' => "${main_pipe_dir}/${blastdb_name}", },
            ],
            -wait_for  => [ 'load_uniprot_factory', 'load_uniprot' ],
        },

        {   -logic_name => 'make_blastdb',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { 
                'blastplus_bin_dir' => $blastplus_bin_dir,
                'work_dir'          => $main_pipe_dir,
            },
            -input_ids => [
                { 'cmd' => "#blastplus_bin_dir#/makeblastdb -dbtype prot -parse_seqids -logfile #work_dir#/makeblastdb.log -in #work_dir#/${blastdb_name}", },
            ],
            -wait_for => [ 'dump_member_proteins' ],
        },

        {   -logic_name => 'copy_blastdb_over',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => {
                'source_dir' => $main_pipe_dir,
                'target_dir' => $lustre_pipe_dir,
            },
            -input_ids => [
                { 'cmd' => "cp #source_dir#/${blastdb_name}* #target_dir#", },
            ],
            -wait_for => [ 'make_blastdb' ],
        },

        {   -logic_name => 'family_blast_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'logic_name' => 'family_blast',
                'inputquery' => 'SELECT DISTINCT s.sequence_id FROM member m, sequence s WHERE m.sequence_id=s.sequence_id AND m.source_name IN ("Uniprot/SPTREMBL", "Uniprot/SWISSPROT", "ENSEMBLPEP") ',
                'step'       => 100,
                'numeric' => 1,
            },
            -input_ids => [
                { 'input_id' => { 'sequence_id' => '$RangeStart', 'minibatch' => '$RangeCount' }, },
            ],
            -wait_for => [ 'copy_blastdb_over' ],
        },

            # NB: jobs will be created by the JobFactory above
        {   -logic_name    => 'family_blast',
            -module        => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyBlast',
            -parameters    => {
                'fastadb'    => "${lustre_pipe_dir}/${blastdb_name}",
                'idprefixed' => 1,
            },
            -hive_capacity => 1000,
            -input_ids     => [
            ],
            -wait_for => [ 'family_blast_factory' ],

            -blocked  => 1, # run this analysis with:
                            #  -logic_name family_blast -lsf_options '-q long -R"select[mycompara2<1000] rusage[mycompara2=10:duration=10:decay=1]"' -lifespan 1200
        },

        {   -logic_name => 'dump_matrix_to_mcxload',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => {
                'mcl_bin_dir'       => $mcl_bin_dir,
                'work_dir'          => $main_pipe_dir,
                'db_conn'           => hash_2_mysql_params($pipeline_db, 1),
            },
            -input_ids  => [
                { 'cmd' => "mysql #db_conn# -N -q -e 'select * from mcl_sparse_matrix' | #mcl_bin_dir#/mcxload -abc - -ri max -o #work_dir#/${tcx_name} -write-tab #work_dir#/${itab_name}", },
            ],
            -wait_for   => [ 'family_blast_factory', 'family_blast' ],

            -blocked  => 1, # run this analysis with:
                            #  -logic_name dump_matrix_to_mcxload -lsf_options '-C0 -M15000000 -R"select[mem>15000] rusage[mem=15000]"' -lifespan 1200
        },

        {   -logic_name => 'mcl',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => {
                'mcl_bin_dir'       => $mcl_bin_dir,
                'work_dir'          => $main_pipe_dir,
            },
            -input_ids => [
                { 'cmd' => "#mcl_bin_dir#/mcl #work_dir#/${tcx_name} -I 2.1 -t 4 -tf 'gq(50)' -scheme 6 -use-tab #work_dir#/${itab_name} -o #work_dir#/${mcl_name}", },
            ],
            -wait_for   => [ 'dump_matrix_to_mcxload' ],

            -blocked  => 1, # run this analysis with:
                            #  -logic_name mcl -lsf_options '-C0 -M50000000 -n 4 -q hugemem -R"select[ncpus>=4 && mem>50000] rusage[mem=50000] span[hosts=1]"' -lifespan 1200
        },

    ],
};

__END__


        {   -logic_name => 'parse_mcl',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => {
            },
            -input_ids => [
            ],
        },

        {   -logic_name => 'family_mafft_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'module' => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyMafft',
                'logic_name' => 'family_mafft',
                'inputquery' => 'SELECT family_id FROM family_member GROUP BY family_id HAVING count(*)>1',
                'randomize' => 1,
                'numeric' => 1,
                'hive_capacity' => 400,
                'batch_size' => 10,
            },
            -input_ids => [
                { 'input_id' => { 'family_id' => '$RangeStart' } },
            ],
        },
        
        # (the previous analysis will create 'family_mafft' analysis & jobs)
        
        # ToDo: paragraphs 12 and 13

        {   -logic_name => '',
            -module     => '',
            -parameters => {
            },
            -input_ids => [
            ],
        },

    ],

};

