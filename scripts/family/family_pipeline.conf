## Configuration file for the MCL family pipeline (development in progress)
#
## Run it like this:
#
# time init_pipeline.pl -conf family_pipeline.conf
# 
# rel.57    6m30

my $release = '57pp';

my $email   = $ENV{'USER'}.'@ebi.ac.uk';    # NB: your EBI address may differ from the Sanger one!

    # code directories:
my $cvs_root_dir      = $ENV{'HOME'}.'/work';
#my $cvs_root_dir      = $ENV{'HOME'}.'/ensembl_main'; ## for some Compara developers

my $old_scripts_dir   = $cvs_root_dir.'/ensembl-compara/scripts/family';

my $sec_root_dir      = '/software/ensembl/compara';
my $mafft_root_dir    = $sec_root_dir . '/mafft-6.522';

my $blast_version     = 'ncbi-blast-2.2.22+';
my $blast_bin_dir     = $sec_root_dir . "/${blast_version}/bin";
my $mcl_bin_dir       = $sec_root_dir . '/mcl-09-308/bin';
    
    # data directories:
my $work_dir        = $ENV{'HOME'}."/family_${release}";
my $blastdb_dir     = '/lustre/scratch103/ensembl/'.$ENV{'USER'}."/family_${release}";
my $blastdb_name    = "metazoa_${release}.pep";
my $tcx_name        = "family_${release}.tcx";
my $itab_name       = "family_${release}.itab";
my $mcl_name        = "family_${release}.mcl";
my $desc_name       = "family_${release}.description";
my $cons_name       = "family_${release}.consensus";

    # family database connection parameters (our main database):
my $pipeline_db = {
    -host   => 'compara2',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    -dbname => "lg4_compara_family_${release}",
};

    # homology database connection parameters (we inherit half of the members and sequences from there):
my $homology_db  = {
    -host   => 'compara3',
    -port   => 3306,
    -user   => 'ensadmin',
    -pass   => 'ensembl',
    # -dbname => "avilella_compara_homology_${release}",
    #
    -dbname => 'avilella_compara_homology_57f',
};

sub dbconn_2_mysql {
    my ($db_conn, $with_db) = @_;

    return "--host=$db_conn->{-host} --port=$db_conn->{-port} "
          ."--user=$db_conn->{-user} --pass=$db_conn->{-pass} "
          .($with_db ? "--database=$db_conn->{-dbname} " : '');
} 

{
        # pass connection parameters into the pipeline initialization script to create adaptors:
    -pipeline_db => $pipeline_db,

        # shell commands that create and pre-fill the pipeline database:
    -pipeline_create_commands => [
        'mysql '.dbconn_2_mysql($pipeline_db, 0)." -e 'CREATE DATABASE $pipeline_db->{-dbname}'",

        'mysql '.dbconn_2_mysql($pipeline_db, 1)." <$cvs_root_dir/ensembl-hive/sql/tables.sql",
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." <$cvs_root_dir/ensembl-hive/sql/procedures.sql",
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." <$cvs_root_dir/ensembl-compara/sql/table.sql",
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." <$cvs_root_dir/ensembl-compara/sql/pipeline-tables.sql",

        'mysqldump '.dbconn_2_mysql($homology_db, 0).' '.$pipeline_db->{-dbname}
                    .' -t ncbi_taxa_name ncbi_taxa_node method_link genome_db species_set method_link_species_set '
                    .'| mysql '.dbconn_2_mysql($pipeline_db, 1),

        'mysqldump '.dbconn_2_mysql($homology_db, 0).' '.$pipeline_db->{-dbname}
                   .' -t member sequence family family_member | sed "s/ENGINE=MyISAM/ENGINE=InnoDB/" '
                   .'| mysql '.dbconn_2_mysql($pipeline_db, 1),

        'mysql '.dbconn_2_mysql($pipeline_db, 1)." -e 'ALTER TABLE member   AUTO_INCREMENT=100000000'",
        'mysql '.dbconn_2_mysql($pipeline_db, 1)." -e 'ALTER TABLE sequence AUTO_INCREMENT=100000000'",

        "mkdir -p $work_dir",
        "mkdir -p $blastdb_dir",
    ],

    -pipeline_wide_parameters => {  # these parameter values are visible to all analyses, can be overridden by parameters{} and input_id{}

        'name'              => "fam${release}",                 # name the pipeline to differentiate the submitted processes
        'db_conn'           => dbconn_2_mysql($pipeline_db, 1), # external connection to this database (for various scripts)
        'email'             => $email,                          # for automatic notifications (may be unsupported by your Meadows)

        'work_dir'          => $work_dir,                       # data directories and filenames
        'blastdb_dir'       => $blastdb_dir,
        'blastdb_name'      => $blastdb_name,

        'blast_bin_dir'     => $blast_bin_dir,                  # binary & script directories
        'mcl_bin_dir'       => $mcl_bin_dir,
        'old_scripts_dir'   => $old_scripts_dir,

        'idprefixed'        => 1,                               # other options to sync different analyses
    },

    -resource_classes => {
         0 => { -desc => 'default, 8h',      'LSF' => '' },
         1 => { -desc => 'urgent',           'LSF' => '-q yesterday' },
         2 => { -desc => 'long compara2',    'LSF' => '-q long -R"select[mycompara2<1000] rusage[mycompara2=10:duration=10:decay=1]"' },
         3 => { -desc => 'high memory',      'LSF' => '-C0 -M25000000 -q hugemem -R"select[mem>25000] rusage[mem=25000]"' },    # 15G enough to load 450mln, 25G enough to load 850mln
         4 => { -desc => 'huge mem 4proc',   'LSF' => '-C0 -M50000000 -n 4 -q hugemem -R"select[ncpus>=4 && mem>50000] rusage[mem=50000] span[hosts=1]"' },
         5 => { -desc => 'himem compara2',   'LSF' => '-C0 -M14000000 -R"select[mycompara2<500 && mem>14000] rusage[mycompara2=10:duration=10:decay=1:mem=14000]"' },
         6 => { -desc => 'compara2',         'LSF' => '-R"select[mycompara2<500] rusage[mycompara2=10:duration=10:decay=1]"' },
    },

    -pipeline_analyses => [
        {   -logic_name => 'load_uniprot_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'logic_name'    => 'load_uniprot',
                'inputlist'     => ['FUN','HUM','MAM','ROD','VRT','INV'],
                'numeric'       =>  0,
            },
            -input_ids => [
                { 'input_id' => { 'srs' => 'SWISSPROT', 'tax_div' => '$RangeStart' } },
                { 'input_id' => { 'srs' => 'SPTREMBL',  'tax_div' => '$RangeStart' } },
            ],
            -rc_id => 1,
        },

        {   -logic_name    => 'load_uniprot',
            -module        => 'Bio::EnsEMBL::Compara::RunnableDB::LoadUniProt',
            -parameters    => { },
            -hive_capacity => 20,
            -input_ids     => [
                # (jobs for this analysis will be created by the JobFactory above)
            ],
            -wait_for  => [ 'load_uniprot_factory' ],
            -rc_id => 0,
        },
        
        {   -logic_name => 'dump_member_proteins',
            -module     => 'Bio::EnsEMBL::Compara::RunnableDB::DumpMemberSequencesIntoFasta',
            -parameters => {
                'source_names' => [ 'ENSEMBLPEP','Uniprot/SWISSPROT','Uniprot/SPTREMBL' ],
            },
            -input_ids => [
                { 'fasta_name' => "${work_dir}/${blastdb_name}", },
            ],
            -wait_for  => [ 'load_uniprot_factory', 'load_uniprot' ],
            -rc_id => 1,
        },

        {   -logic_name => 'make_blastdb',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids => [
                { 'cmd' => "#blast_bin_dir#/makeblastdb -dbtype prot -parse_seqids -logfile #work_dir#/makeblastdb.log -in #work_dir#/#blastdb_name#", },
            ],
            -wait_for => [ 'dump_member_proteins' ],
            -rc_id => 1,
        },

        {   -logic_name => 'copy_blastdb_over',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids => [
                { 'cmd' => "cp #work_dir#/#blastdb_name#* #blastdb_dir#", },
            ],
            -wait_for => [ 'make_blastdb' ],
            -rc_id => 1,
        },

        {   -logic_name => 'family_blast_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'logic_name' => 'family_blast',
                'inputquery' => 'SELECT DISTINCT s.sequence_id FROM member m, sequence s WHERE m.sequence_id=s.sequence_id AND m.source_name IN ("Uniprot/SPTREMBL", "Uniprot/SWISSPROT", "ENSEMBLPEP") ',
                'step'       => 100,
                'numeric' => 1,
            },
            -input_ids => [
                { 'input_id' => { 'sequence_id' => '$RangeStart', 'minibatch' => '$RangeCount' }, },
            ],
            -wait_for => [ 'copy_blastdb_over' ],
            -rc_id => 1,
        },

        {   -logic_name    => 'family_blast',
            -module        => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyBlast',
            -parameters    => { },
            -hive_capacity => 1000,
            -input_ids     => [
                # (jobs for this analysis will be created by the JobFactory above)
            ],
            -wait_for => [ 'family_blast_factory' ],
            -rc_id => 2,
        },

        {   -logic_name => 'mcxload_matrix',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids  => [
                { 'cmd' => "mysql #db_conn# -N -q -e 'select * from mcl_sparse_matrix' | #mcl_bin_dir#/mcxload -abc - -ri max -o #work_dir#/${tcx_name} -write-tab #work_dir#/${itab_name}", },
            ],
            -wait_for => [ 'family_blast_factory', 'family_blast' ],
            -rc_id => 3,
        },

        {   -logic_name => 'mcl',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids => [
                { 'cmd' => "#mcl_bin_dir#/mcl #work_dir#/${tcx_name} -I 2.1 -t 4 -tf 'gq(50)' -scheme 6 -use-tab #work_dir#/${itab_name} -o #work_dir#/${mcl_name}", },
            ],
            -wait_for => [ 'mcxload_matrix' ],
            -rc_id => 4,
        },

        {   -logic_name => 'parse_mcl',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -input_ids => [
                { 'cmd' => "#old_scripts_dir#/parse_mcl.pl #db_conn# -mclfile #work_dir#/${mcl_name} >#work_dir#/${desc_name} 2>#work_dir#/${desc_name}.err", },
            ],
            -wait_for => [ 'mcl' ],
            -rc_id => 1,
        },

# 1. Archiving sub-branch:
        {   -logic_name => 'archive_long_files',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'cmd' => "gzip #work_dir#/${tcx_name}", },
                { 'cmd' => "gzip #work_dir#/${itab_name}", },
                { 'cmd' => "gzip #work_dir#/${mcl_name}", },
            ],
            -wait_for => [ 'parse_mcl' ],
            -rc_id => 1,
        },
# (end of branch 1)

# 2. Mafft sub-branch:
        {   -logic_name => 'family_mafft_factory',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::JobFactory',
            -parameters => {
                'randomize'  => 1,
                'numeric'    => 1,
                'input_id'   => { 'family_id' => '$RangeStart' },
            },
            -input_ids  => [
                { 'logic_name' => 'family_mafft_big',  'inputlist'  => [ 1, 2 ],},
                { 'logic_name' => 'family_mafft_main', 'inputquery' => 'SELECT family_id FROM family_member WHERE family_id>2 GROUP BY family_id HAVING count(*)>1',},
            ],
            -wait_for => [ 'parse_mcl' ],
            -rc_id => 1,
        },

        {   -logic_name    => 'family_mafft_big',
            -module        => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyMafft',
            -parameters    => { },
            -batch_size    => 1,
            -input_ids     => [
                # (jobs for this analysis will be created by the JobFactory above)
            ],
            -wait_for => [ 'family_mafft_factory' ],
            -rc_id => 5,
        },

        {   -logic_name    => 'family_mafft_main',
            -module        => 'Bio::EnsEMBL::Compara::RunnableDB::FamilyMafft',
            -parameters    => { },
            -hive_capacity => 400,
            -batch_size    =>  10,
            -input_ids     => [
                # (jobs for this analysis will be created by the JobFactory above)
            ],
            -wait_for => [ 'family_mafft_factory' ],
            -rc_id => 6,
        },

        {   -logic_name => 'find_singletons',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SqlCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'sql' => "CREATE TABLE singletons SELECT family_id, length(s.sequence) len, count(*) cnt FROM family_member fm, member m, sequence s WHERE fm.member_id=m.member_id AND m.sequence_id=s.sequence_id GROUP BY family_id HAVING cnt=1", },
            ],
            -wait_for => [ 'family_mafft_big', 'family_mafft_main' ],
            -rc_id => 1,
        },

        {   -logic_name => 'update_singleton_cigars',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SqlCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'sql' => "UPDATE family_member fm, member m, singletons st SET fm.cigar_line=concat(st.len, 'M') WHERE fm.family_id=st.family_id AND m.member_id=fm.member_id AND m.source_name<>'ENSEMBLGENE'", },
            ],
            -wait_for => [ 'find_singletons' ],
            -rc_id => 1,
        },

        {   -logic_name => 'insert_redundant_pep_genes',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'cmd' => "#old_scripts_dir#/InsertRedundantPeptidesAndGenesInFamilies.pl #db_conn# >#work_dir#/Redundancy_and_Genes_load.err 2>&1", },
            ],
            -wait_for => [ 'update_singleton_cigars' ],
            -rc_id => 1,
        },
# (end of branch 2)

# 3. Consensifier sub-branch:
        {   -logic_name => 'consensifier',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'cmd' => "#old_scripts_dir#/consensifier.pl -d Uniprot/SWISSPROT #work_dir#/${desc_name} >#work_dir#/${cons_name}-SWISSPROT 2>#work_dir#/${cons_name}-SWISSPROT.err", },
                { 'cmd' => "#old_scripts_dir#/consensifier.pl -d Uniprot/SPTREMBL  #work_dir#/${desc_name} >#work_dir#/${cons_name}-SPTREMBL  2>#work_dir#/${cons_name}-SPTREMBL.err", },
            ],
            -wait_for => [ 'parse_mcl' ],
            -rc_id => 1,
        },

        {   -logic_name => 'assemble_consensus',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'cmd' => "#old_scripts_dir#/assemble-consensus.pl #work_dir#/${desc_name} #work_dir#/${cons_name}-SWISSPROT #work_dir#/${cons_name}-SPTREMBL >#work_dir#/${cons_name} 2>#work_dir#/${cons_name}.err", },
            ],
            -wait_for => [ 'consensifier' ],
            -rc_id => 1,
        },

        {   -logic_name => 'load_family_descriptions',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::SystemCmd',
            -parameters => { },
            -hive_capacity => 20, # to enable parallel branches
            -input_ids => [
                { 'cmd' => "#old_scripts_dir#/LoadDescriptionInFamily.pl #db_conn# -descfile #work_dir#/${cons_name} 2>#work_dir#/${cons_name}.load_err", },
            ],
            -wait_for => [ 'assemble_consensus' ],
            -rc_id => 1,
        },
# (end of branch 3)

# final job funnel:
        {   -logic_name => 'notify_pipeline_completed',
            -module     => 'Bio::EnsEMBL::Hive::RunnableDB::NotifyByEmail',
            -parameters => { },
            -input_ids => [
                { 'subject' => 'FamilyPipeline has completed', 'text' => "This is an automatic message.\nFamilyPipeline has completed.", },
            ],
            -wait_for => [ 'archive_long_files', 'insert_redundant_pep_genes', 'load_family_descriptions' ],
            -rc_id => 1,
        },

    ],
};

