
1- code API needed and executable
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bioperl-live
ensembl
ensembl-compara

executables
~~~~~~~~~~~
blastall
	using /usr/local/ensembl/bin/blastall

mcl (source can be obtained from http://micans.org/mcl/src/)
	using /nfs/acari/avilella/bin/mcxdeblast
	using /nfs/acari/avilella/bin/mcxassemble
	using /nfs/acari/avilella/bin/mcx
	using /nfs/acari/avilella/bin/mcl

2- Choose a working directory with enough disk space
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The family pipeline takes several GB of space (5GB should be sufficient). (df -k)

mkdir -p /lustre/scratch1/ensembl/lg4/families/family_54
cd /lustre/scratch1/ensembl/lg4/families/family_54
mkdir tmp fasta blast_in blast_out blast_raw mcl muscle clustalw_mpi

3- Loading in and dumping from compara the peptides
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The loading of ensembl peptides/genes and uniprot is now done as a common trunk with the gene homology pipeline.
# The loading process will identify redundant proteins using a MySQL index trick and assign to them the same 
# sequence_id. Very clever indeed!

# Before loading, make sure that in each core db:
# a) stable ids are in (look in tables 'exon_stable_id', 'translation_stable_id', 'transcript_stable_id' 
#    and 'gene_stable_id')

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_54" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select * from exon_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from translation_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from transcript_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from gene_stable_id limit 10"; echo "---"; done | less

# b) species data in 'meta' table up to date

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_54" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select * from meta" | grep species; echo "---"; done | less

# c) check the gene type e.g. pseudogene or RNA that you don't want to load and update the filter out condition if necessary

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_54" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select count(*) as number, biotype from gene group by biotype order by number desc"; echo "---"; done | less

# NB: need to add something here on how to load or a reference to homology documentation

# The dumping is done with ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl script.
# Don't use -noX or nosplit, use the default setting. The dumping process will dump only one version of each sequence,
# so no redundancy is expected in the fasta file.

# Go to the fasta dir
# Make it faster for big files in lsf
# lfs setstripe fasta 0 -1 -1
# cd fasta

# Or move it to (depending on the blast filesystem services you've got)
mkdir -p /data/blastdb/Ensembl/family_54/fasta
cd /data/blastdb/Ensembl/family_54/fasta

# Takes about 2 minutes
perl ~avilella/src/ensembl_main/ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl -conf /lustre/work1/ensembl/avilella/hive/avilella_compara_homology_54/genetree_all.conf --noredundancy -fasta metazoa_54.pep > metazoa_54.pep.err 2>&1 &

# or if you don't have the hive conf file
perl ~avilella/src/ensembl_main/ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl --dbhost compara2 --dbport 5316 --dbuser ensro --dbname avilella_compara_homology_54 --noredundancy --fasta metazoa_54.pep > metazoa_54.pep.err 2>&1 &

grep '>' metazoa_54.pep | wc -l
#v54 2188240
#v5? 2023775
#v51 1811409
#v50 1695699
#v49 1653108
#v48 1520968

4- Format file for blast
   ~~~~~~~~~~~~~~~~~~~~~

# Takes about 16 seconds for rel54
fastaindex metazoa_54.pep metazoa_54.index

# Takes about 5 minutes
bsub -o /dev/null -q yesterday 'formatdb -p T -l metazoa_54.pep.formatdb.log -i metazoa_54.pep'

# check metazoa_54.pep.formatdb.log if it is ok delete it

# Formatted 2023775 sequences in volume 0

rm -f metazoa_54.pep.formatdb.log

# Create the index file for future run of mcl

# Takes about 4 seconds
awk 'BEGIN {idx=0} {print idx,$1;idx++}' metazoa_54.index > metazoa_54.tab

5- Prepare files to run blastp
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd /lustre/scratch1/ensembl/lg4/families/family_54/blast_in

# Distribute peptide ids in several files. Each of them will contain 100 ids,
# and would correspond to one blastp job.

# Takes about 1 minute
perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/SplitPeptides.pl -maxids 250 /data/blastdb/Ensembl/family_54/fasta/metazoa_54.index

#   The created files are named: PeptideSet.1, PeptideSet.2, ..., PeptideSet.n
#   so that they are suitable for LSF job array creation. 
 

6- Run blastp with in a LSF jobs array
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# For info on jobs array, see
# http://www.sanger.ac.uk/campus/IT/ISG/lsf/job-arrays.shtml
# 
# NB: not done yet, think about putting out the SEG filter in blastp as we do for homologous genepairs, not sure
# that is a good idea. Replace SEG by CAST filtering.
# 
#  The script used to run individual blastp is
#  ensembl-compara/scripts/family/LaunchBlast.pl
# 
#  At the beginning of the script, you may need to update few lines that specifie the path
#  for the executable to be used
# 
# my $blast_executable
# my $fastafetch_executable
# my $blast_parser_executable

ls ../blast_in |wc -l
# v54 8753
# v5? 8032
# v51 7246
# v50 6783
# v49 6613
# v48 6084

# will tell you how many jobs have to be run. Just have a try with one to make sure everything is ok.
#
# It is better to place the output files in a different directory to reduce the burden on the filesystem.
# (The fewer files per directory the better).

# BDir /data/blastdb/Ensembl/family_54/fasta
# Ldir /lustre/scratch1/ensembl/lg4/families/family_54/fasta

# lg4: the following looks like an important omission:
#      But I wonder if the /data/blastdb/Ensembl/family_xx/fasta directory was needed in the first place?
#
cp /data/blastdb/Ensembl/family_54/fasta/* /lustre/scratch1/ensembl/lg4/families/family_54/fasta/

# LaunchBlast will run like this: system("/usr/local/ensembl/bin/blastall -d $fastadb -i $qy_file -p blastp -e 0.00001 -v 250 -b 0 > $blast_file");
# where:
#   -e  Expectation value (E) [Real]
#   -v  Number of database sequences to show one-line descriptions for (V) [Integer]
#   -b  Number of database sequence to show alignments for (B) [Integer]

# This will run the first one to check if everything is working properly -- you can use "strace -p pid" to inspect your job in the cluster node

echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp"[1]" -o ../blast_out/PeptideSet.%I.out

# Check that the BLASTMAT points to /usr/local/ensembl/data/blastmat

echo $BLASTMAT

# When it is complete, you should get 2 new files

../blast_out/PeptideSet.1.out
../blast_raw/PeptideSet.1.raw.gz

# The first is the STDOUT from LSF. The latter is the blastp output parsed (and zipped)
# in the suitable format needed for the following steps.

# To check if the job finished properly

cd ../blast_out
ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done|awk '{print $2}'|sort |uniq -c

# That gives you the number of jobs "Done" and "Exited" if any.

# Then run the whole lot of jobs

# Look for the last PeptideSet.NNNN
ls | awk -F\. '{print $2}' | sort -n | tail

# This will run the rest of the jobs up to 8753
cd ../blast_in
echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp"[2-8753]" -o ../blast_out/PeptideSet.%I.out

# Rerun the failed jobs in ../blast_out.

cd ../blast_out

ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done > ../job_status

grep Exited ../job_status | awk 'BEGIN {FS="."} {print $2}' | sort -n -u >../first_batch.ids

# create the compressed list of ids to be used by bjobs:
awk 'BEGIN {s=0;e=0;i=1;c=""} s==0 {s=$1;e=$1;c=s;next} $1==e+1 {e=$1;c=s"-"e;next} $1>e+1 {printf c ((i%15)?",":"\n");s=$1;e=$1;c=s;i++;next} END {print c}' ../first_batch.ids >../first_batch_ids.collapsed

cd ..

# Because this only checks the out files, you can resubmit safely even if you still have running jobs, that haven't produced an out file yet:
grep Exited job_status |awk '{print $1}'|while read i;do rm -f blast_out/$i;done

cat first_batch_ids.collapsed | while read i;do echo "echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub

# Then move to blast_in and resubmit the failed jobs

cd blast_in
bash rebsub


# Sometimes you get jobs that fail because they failed previously and you forgot to remove the output files.
# Check if you have any of such files:

cd ..
grep -lr 'Job already finished' blast_out >second_batch.filenames

# If the file is empty - just go to step 8. Otherwise:

# create the list of the ids:
awk 'BEGIN {FS="."} {print $2}' second_batch.filenames | sort -n -u >second_batch.ids

# compress it:
awk 'BEGIN {s=0;e=0;i=1;c=""} s==0 {s=$1;e=$1;c=s;next} $1==e+1 {e=$1;c=s"-"e;next} $1>e+1 {printf c ((i%15)?",":"\n");s=$1;e=$1;c=s;i++;next} END {print c}' second_batch.ids >second_batch_ids.collapsed

# actually remove the offending files (both out- and raw-files) (may want a while-read-do-rm solution for longer files?):
rm `cat second_batch.filenames`
rm `cat second_batch.filenames | sed "s/blast_out/blast_raw/" | sed "s/.out/.raw.gz/"`

# re-create the submission commands:
cat second_batch_ids.collapsed | while read i;do echo "echo '/nfs/team71/analysis/lg4/work/ensembl-compara/scripts/family/LaunchBlast.pl -baexec /software/ensembl/compara/blast-2.2.6/blastall -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.pep -fastaindex /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.index -tab /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab -dir /lustre/scratch1/ensembl/lg4/families/family_54/blast_raw/' | bsub -q long -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub2

# actually submit the jobs:
cd blast_in
bash rebsub2

8- Build the matrix needed by mcl and check it for symmetry
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../blast_raw

# Takes about 8-10 minutes, do on a farm node
# Took 25 seconds with stijn parameters
export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err 'find -name "*.raw.gz"|xargs gunzip -c > ../mcl/family_54.raw'

cd ../mcl

# create a symlink to /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab

ln -s /lustre/scratch1/ensembl/lg4/families/family_54/fasta/metazoa_54.tab family_54.tab

# create a family_54.hdr header file,
# The dimensions should be the number of peptides. That can be obtained by

# wc -l family_54.raw
# 2007943 family_54.raw
# lg4@bc-9-1-03:/lustre/scratch1/ensembl/lg4/families/family_54/mcl$ wc -l family_54.tab
# 2023775 family_54.tab

wc -l family_54.tab
# v54 ....... family_54.tab
# v5? 2023775 family_5?.tab
# v51 1811409 family_51.tab
# v50 1695699 family_50.tab
# v49 1653108 family_49.tab
# v48 1520968 family_48.tab


cat > family_54.hdr
(mclheader
mcltype matrix
dimensions 2023775x2023775
)

# This takes not 30 min but about 8-10 minutes now that we have bigmem
# fast nodes, and will generate a family_54.bin matrix file.
export TIMESTAMP=`date +2%3y%m%d_%H%M%S`
bsub -o $TIMESTAMP.out -e $TIMESTAMP.err '~avilella/src/ensembl_main/ensembl-compara/scripts/family/mcxassemble.sh family_54'

# 50 min -- tcx file using lots of memory in turing -- bin is machine-dependent -- tcx is cross-machine compatible
export TIMESTAMP=`date +2%3y%m%d_%H%M%S`
bsub -o $TIMESTAMP.out -e $TIMESTAMP.err '~avilella/src/ensembl_main/ensembl-compara/scripts/family/mcxassemble.sh.tcx family_54'

cd /lustre/scratch1/ensembl/lg4/families/family_54/mcl
# The home directory is visible to turing, so it's more convenient and doesn't take that much space
mkdir ~/family_54/
cp -f family_54.hdr ~/family_54/
cp -f family_54.tab ~/family_54/
cp -f family_54.raw ~/family_54/
cd  ~/family_54/

# Check that everything is all right in family_54.mcxassemble.err

# We don't need the raw file anymore and as it takes quite a lot of space, delete it.

rm -f family_54.raw

9- Run mcl
   ~~~~~~~

This step uses turing which has 192Gb of memory :))) and 16 CPUs. As mcl can be multi-threaded, it is very useful.

Try to use 12 cpus, less if available in the hugemem queue, try to use lots of RAM, less if available:

for n in `seq 12 -1 1`
do
        for mem in `seq 95000 -20000 35000`
        do
                sleep 1
                hmem=$(($mem * 1000))
                # old method
                # export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err -C0 -R "select[ncpus>=$n && mem>$mem] rusage[mem=$mem] span[hosts=1]" -M$hmem -q hugemem -n $n "/nfs/acari/avilella/src/mcl-08-152/src/shmcl/mcl ~/family_54/family_54.tcx -I 2.1 -t $n -P 10000 -S 1000 -R 1260 -pct 90 -o ~/family_54/family_54.mcl.turing.pct90.$n.$mem.$TIMESTAMP"
                # new method
                export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err -C0 -R "select[ncpus>=$n && mem>$mem] rusage[mem=$mem] span[hosts=1]" -M$hmem -q hugemem -n $n "/nfs/acari/avilella/src/mcl-08-152/src/shmcl/mcl ~/family_54/family_54.tcx -I 2.1 -t $n -tf 'gq(50)' -scheme 6 -o ~/family_54/family_54.mcl.turing.gq50.6.$n.$mem.$TIMESTAMP"
                done
done

# Once you have one of the jobs running, kill the remaining pending jobs with "bkill jobid".

# turing old method (v48 and before)
# export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bsub -o $TIMESTAMP.out -e $TIMESTAMP.err -C0 -R 'select[ncpus>=8 && mem>10000 && type==LINUX64] rusage[mem=10000] span[hosts=1]' -q hugemem -n 8 -f "family_54.bin > /tmp/family_54.bin" -f "family_54.mcl < /tmp/family_54.mcl" -o mcl.out /nfs/acari/abel/bin/arch-ia64/mcl /tmp/family_54.bin -I 2.1 -t 8 -P 10000 -S 1000 -R 1260 -pct 90 -o /tmp/family_54.mcl

# NB: whenever you have finished running mcl (maybe with different parameters), don't forget 
# to delete /tmp/family_50.* from aristotle /tmp (a shell script having the flavour of 
# mcxassemble.sh or mcx.sh could do it automatically...not very useful though if several mcl run have to be tested)

10- Load into compara database
    ~~~~~~~~~~~~~~~~~~~~~~~~~

# You'll need a compara database set up, with genome_db, taxon, and method_link tables prefilled.

# Edit the reg_conf.50.pl to point to the compara_homology db
/lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf.54.pl

# Your reg_conf.pl should be something like

use strict;
use Bio::EnsEMBL::Utils::ConfigRegistry;
use Bio::EnsEMBL::Compara::DBSQL::DBAdaptor;

new Bio::EnsEMBL::Compara::DBSQL::DBAdaptor(-host => 'compara2',
                                            -user => 'ensadmin',
                                            -pass => 'ensembl',
                                            -port => 3306,
                                            -species => 'compara54',
                                            -dbname => 'avilella_compara_homology_54');
1;

# This takes around an hour, and you can not do anything else before the loading is completed.

nohup ~avilella/src/ensembl_main/ensembl-compara/scripts/family/parse_mcl.pl --dbname compara54 --reg_conf /lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf.54.pl family_54.tab family_54.mcl -prefix fam54 > family_54.description 2> family_54.description.err &

# To save space,

bsub 'gzip family_54.mcl'

11- Run muscle or clustalw over all the families
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# !!!Step 13 should be run also at the same time. It is not dependant on multiple alignments.

mysql -hcompara2 -uensro avilella_compara_homology_54 -e "select count(*), family_id from family_member where cigar_line IS NULL group by family_id having count(*)>1" | wc -l
80681
# v51 74656
# v50 72676
# v49 6413
# v48 44852
# v47 43834

cd /lustre/scratch1/ensembl/lg4/families/family_54/

# Get a list of all the family ids with more than one member. If you get it in random order, then the size of each id will be randomly spread in the list, and the jobs
# will be more randomly distributed in terms of CPU time
mysql -hcompara2 -uensro avilella_compara_homology_54 -N -e "select family_id from family_member group by family_id having count(*)>1 order by RAND()" > family_ids_rand.txt

# I use a generic hive database for uploading the jobs. Each job is a LaunchMafft_batch.pl iwth a family id in the list
perl /nfs/acari/avilella/src/ensembl_main/ensembl-personal/avilella/hive/cmd_hive.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -input_id 'perl /nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchMafftOnFamilies_batch.pl -h compara2 -db avilella_compara_homology_54 -u ensadmin -ps ensembl -f $inputfile -n 1 -s' -inputfile /lustre/scratch1/ensembl/lg4/families/family_54/family_ids_rand.txt -hive_capacity 200 -batch_size 5 -logic_name family_mafft_54_1

export PATH=$PATH:/nfs/acari/avilella/src/ensembl_main/ensembl-hive/scripts/
beekeeper.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -sync

beekeeper.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -lsf_options '-R"select[mycompara2<500] rusage[mycompara2=10:duration=10:decay=1]"' -lifespan 1200 -loop -logic_name family_mafft_54_1

# The last ~1000 should be done with lots of memory:
beekeeper.pl -url mysql://ensadmin:ensembl@compara2/avilella_hive_generic -lsf_options '-R"select[mycompara2<500 && mem>15000] rusage[mycompara2=10:duration=10:decay=1:mem=15000]" -M15000000' -lifespan 1200 -loop -logic_name family_mafft_54_1

# When the alignments fail with mafft, you can resort to clustalw:

The same kind of script but running CLUSTALW also exists, ensembl-compara/scripts/family/LaunchMuscleOnFamilies.pl

And if then again it does not work, run clustalw_mpi (see below).

clustalw_mpi
============

In cases of big families that did not finish with muscle or single-cpu clustalw, you can start clustal_mpi runs while letting
their muscle/single-cpu clustalw jobs running.
mpi_clustalw is a parallelized version of clustalw (that is installed on bc nodes).
As the mpi version is working is rsh command, you want to make sure that you have a ~/.rhosts that contains at least this

+@bc_hosts

and have particular read/write access 

chmod go-rwx ~/.rhosts

So now what to do e.g. for family_id=1

cd ../clustalw_mpi

mysql -h compara2 -P3306 -N -u ensro -e "select m.stable_id from member m, family_member fm where m.member_id=fm.member_id and fm.family_id=1" avilella_compara_homology_47 > 1.ids

fastafetch /lustre/scratch1/ensembl/lg4/families/family_47/fasta/metazoa_47.pep /lustre/scratch1/ensembl/lg4/families/family_47/fasta/metazoa_47.index -F true 1.ids > 1.ids.pep

bsub  -o 1.out -n10 -R"linux span[ptile=2]" ~avilella/src/ensembl_main/ensembl-compara/scripts/family/run_clustalw_mpi.sh 1.ids.pep

NB: span[ptile=2] tells NFS to use 2CPU's per machine 
-n10 tells NFS that you will use 10 CPUs. There is no clear algorithm to choose the right number of CPUs to be used depending on the number of sequences. The more sequences you have the less efficient the mpi implementation is. Guy Coates did some testing

9658 seq 10 CPUs ~14hr
9658 seq 16 CPUs ~13hr
So no much gain from 10 to 16.
1690 seq 10 CPUs ~10min
1690 seq 16 CPUs ~7min

For the largest families we released, I've got that
7015 seq 10 CPUs ~11 hours
4736 seq 10 CPUs  ~5 hours

So as a rule of the thumb, I will recommend
10 CPUs when >=5000 sequences
20 CPUs when <=5000 sequences

Never use over 20 CPUs.

If everything worked fine, you should get 3 additional files, 1.out (the busb output) and 
1.ids.dnd, 1.ids.pep.clw, the clustalw outputs.

To Load the clustalw alignment, first check that the  muscle/single-cpu clustal job did not finish properly (if so
you're done with this family), if not bkill it before loading.
/nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchClustalwOnFamilies.pl -host compara2 -port 3306 -dbname avilella_compara_homology_45 -dbuser ensadmin -dbpass ensembl -family_id 1 -clustal_file 1.ids.pep.clw -store > 1.ids.pep.clw.load 2>&1 &

12- Insert the redundant proteins in the compara db
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../fasta

First, set all singletons cigar_line to the length(m.sequence) + "M", because some singletons will disappear with the addition of redundant sequences.

mysql -h compara2 -u ensro -P3306 -N -e "select family_id,count(*) as count from family_member group by family_id having count=1" avilella_compara_homology_54 | awk '{print "select family_id, length(s.sequence) from member m,family_member fm, sequence s where fm.member_id=m.member_id and fm.family_id="$1" and s.sequence_id = m.sequence_id;"}'|mysql -h compara2 -u ensro -P3306 -N avilella_compara_homology_54 |awk '{print "update family_member set cigar_line=\""$2"M\" where family_id="$1";"}'|sort -u > /tmp/update_singletons_cigar_line.sql

mysql -h compara2 -uensadmin -pensembl -P3306 avilella_compara_homology_54 < update_singletons_cigar_line.sql

perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/InsertRedundantPeptidesAndGenesInFamilies.pl --reg_conf /lustre/scratch1/ensembl/lg4/families/_family_54/mcl/reg_conf.54.pl --dbname compara54 > Redundancy_and_Genes_load.err 2>&1 &

IMPORTANT: add healthcheck about NULL cigar_line
mysql -hcompara2 -uensro avilella_compara_homology_54 -e "select m.source_name,count(*) from family_member fm, member m where fm.member_id=m.member_id and fm.cigar_line is NULL group by m.source_name"

This should return count for ENSEMBLGENE;

mysql -hcompara2 -uensro avilella_compara_homology_54 -e "select fm.family_id,count(*) from family_member fm, member m where fm.member_id=m.member_id and fm.cigar_line is NULL and m.source_name!='ENSEMBLGENE' group by fm.family_id"

This should only list the families for which multiple alignment could not be run.

# E.g.:
# +-----------+----------+
# | family_id | count(*) |
# +-----------+----------+
# |       178 |      691 | 
# +-----------+----------+

13- Generates the family descriptions
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    This part really sucks and need a profound rethinking to get the description more clean and consistant.

       ensembl-compara/scripts/family/consensifier.pl 
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       # This step takes approx 2 hours total
       cd mcl
       perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/consensifier.pl -d "Uniprot/SWISSPROT" family_54.description > family_54.description.SWISSPROT-consensus 2> family_54.description.SWISSPROT-consensus.err
       perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/consensifier.pl -d "Uniprot/SPTREMBL" family_54.description > family_54.description.SPTREMBL-consensus 2> family_54.description.SPTREMBL-consensus.err

       ensembl-compara/scripts/family/assemble-consensus.pl
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/assemble-consensus.pl family_54.description family_54.description.SWISSPROT-consensus family_54.description.SPTREMBL-consensus  > family_54.description-consensus 2> family_54.description-consensus.err


update the family description in ensembl_family_54 with the data in family_54.description-consensus using ensembl-compara/scripts/family/LoadDescriptionInFamily.pl 
Use the same reg_cong.pl as in step 11

perl ~avilella/src/ensembl_main/ensembl-compara/scripts/family/LoadDescriptionInFamily.pl --reg_conf /lustre/scratch1/ensembl/lg4/families/family_54/mcl/reg_conf.54.pl --dbname compara54 family_54.description-consensus


