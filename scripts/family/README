
1- code API needed and executable
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bioperl-live (bioperl-1-2-0?)
ensembl
ensembl-compara

executables
~~~~~~~~~~~
blastall
	using /usr/local/ensembl/bin/blastall

mcl (source can be obtained from http://micans.org/mcl/src/)
	using /nfs/acari/abel/bin/mcxdeblast
	using /nfs/acari/abel/bin/mcxassemble
	using /nfs/acari/abel/bin/mcx
	using /nfs/acari/abel/bin/mcl

2- Choose a working directory with enough disk space
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The family pipeline takes several GB of space (5BG should be sufficient). (df -k)

mkdir /acari/work7a/abel/family_20_1
cd /acari/work7a/abel/family_20_1
mkdir tmp srs blast_in blast_out blast_raw mcl clustalw clustalw_mpi

3- get the SWISSPROT and SPTREMBL proteins
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd srs

 You will need to have them in SWISSPROT format. We use to get them through SRS

Make sure you have this line in the your ~/.cshrc file in ice.ebi.ac.uk

if ( -f /ebi/services/pkgs/srs/etc/prep_srs ) then
    source /ebi/services/pkgs/srs/etc/prep_srs
endif

That will make sure you have all the setting ready to use srs (with getz)

 For SWISSPROT

ssh ice.ebi.ac.uk 'getz -e -sf swiss "((([libs={swissprot}-Organism: metazoa] ! [libs={swissprot}-Organism: */*]) ! [libs={swissprot}-Organism: *'\''*]) & [libs-SeqLength# 80:])"' |grep -v "^-"| gzip -c > metazoa.swissprot.gz

 For SPTREMBL

ssh ice.ebi.ac.uk 'getz -e -sf swiss "((([libs={sptrembl}-Organism: metazoa] ! [libs={sptrembl}-Organism: */*]) ! [libs={sptrembl}-Organism: *'\''*]) & [libs-SeqLength# 80:])"' |grep -v "^-"| gzip -c > metazoa.sptrembl.gz

 if you want to know how many sequences you are going to get add the -c option (c for count)

 NB: maybe add in the srs a regexp to take out taxons like 104749, Idiocerinae gen. sp.

4- Format SWISSPROT/SPTREMBL files to get fasta and description file

NB This needs bioperl 1.2

~/src/ensembl_main/ensembl-compara/scripts/family/GetSeqAndDescription.pl -swiss metazoa.swissprot.gz -sptrembl metazoa.sptrembl.gz -fasta metazoa.pep -desc metazoa.desc > metazoa.err 2>&1 &

The description file looks like

swissprot       128U_DROME      GTP-binding protein 128UP.      taxon_id=7227;taxon_genus=Drosophila;taxon_species=melanogaster;taxon_sub_species=;taxon_common_name=Fruit fly;taxon_classification=melanogaster:Drosophila:Drosophilidae:Ephydroidea:Muscomorpha:Brachycera:Diptera:Endopterygota:Neoptera:Pterygota:Insecta:Hexapoda:Arthropoda:Metazoa:Eukaryota
swissprot       1431_SCHMA      14-3-3 protein homolog 1.       taxon_id=6183;taxon_genus=Schistosoma;taxon_species=mansoni;taxon_sub_species=;taxon_common_name=Blood fluke;taxon_classification=mansoni:Schistosoma:Schistosomatidae:Schistosomatoidea:Strigeidida:Digenea:Trematoda:Platyhelminthes:Metazoa:Eukaryota

5- get the Ensembl peptide predictions -- This section has been replaced by a peptide and description dump from the member table which will have been filled already for the homology pipeline.
The script to use is ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl (don't use -noX or nosplit, use the default setting for these)

~/src/ensembl_main/ensembl-compara/scripts/comparaDumpAllPeptides.pl -conf your-compara-hive.conf -fasta ensembl.pep

If so go to point 6 

Requirements: make sure all Ensembl core databases have
a) stable ids (look in tables 'exon_stable_id', 'translation_stable_id', 
               'transcript_stable_id' and 'gene_stable_id')
b) pseudogene flaging (type "pseudogene" may appear in 'gene' table, check with the genebuilder)
c) species data in 'meta' table up to date

Generate a list of the core databases on on ecs2d. If some haven't arrived there yet you may have
to add them manually:
mysql -h ecs4 -P3351 -u ensro -N -B -e 'show databases like "%_core_20_%"' > core_dbs

Modify core_dbs file to add assembly type as 2nd column. It will be used to create the fasta and desc files.
The file should look like that, 2 columns

> more core_dbs
anopheles_gambiae_core_20_2b Ag2b
caenorhabditis_briggsae_core_20_25 Cb25
caenorhabditis_elegans_core_20_116 Ce116
danio_rerio_core_20_3 Dr3
drosophila_melanogaster_core_20_3a Dm3a
fugu_rubripes_core_20_2a Fr2a
homo_sapiens_core_20_34b Hs34b
mus_musculus_core_20_32 Mm32
rattus_norvegicus_core_20_3b Rn3b

nohup cat core_dbs | awk '!/^#/' | while read i j;do /nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/dumpTranslation.pl -host ecs2d -port 3306 -dbname $i -file $j.pep -taxon_file $j.desc > $j.dump.err 2>&1 ;done > alldumps.err 2>&1 &       

check the peptide numbers you get to see if they are what it is expected. Translation like X+ are not kept in the dumps. 

That will dump a FASTA file with this kind of header
>ENSP00000155093 Transcript:ENST00000155093 Gene:ENSG00000067646 Chr:Y Start:2729728 End:2756029

6- concatenate all fasta and desc files
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

gzip *.desc
gunzip -c *.desc.gz | gzip -c > metazoa_20_1.desc.gz
gzip *.pep
gunzip -c *.pep.gz > /data/blastdb/Ensembl/family/metazoa_20_1.pep
fastaindex /data/blastdb/Ensembl/family/metazoa_20_1.pep /data/blastdb/Ensembl/family/metazoa_20_1.index

6A- removing redundancy in the fasta file
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Do that on whatever ecs2 nodes only.
Remove redundant entries before running the blastp

bsub -m ecs2_hosts -o metazoa_20_1.RedundantIds.err ~/src/ensembl_main/ensembl-compara/scripts/family/GenerateNonRedudantSet.pl /data/blastdb/Ensembl/family/metazoa_20_1.pep /data/blastdb/Ensembl/family/metazoa_20_1.index /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep metazoa_20_1.RedundantIds

Generate the mcl entry index

grep ">"  /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep| cut -c -100 | sed "s/^>//" |awk '{print $1}'|sort -u|awk 'BEGIN {idx=0} {print idx,$1;idx++} END {}' > metazoa_20_1_nr.tab


 Do that from an ecs2d node. Not yet, but you'll to send a mail to ensembl-admin@ebi.ac.uk
 and ssg-isg@sanger.ac.uk to ask the distribution of the /data/blastdb/Ensembl/family 
 contains over the farm.

cd /data/blastdb/Ensembl/family/

 Do not forget to delete older version files.
 Format in NCBI blast format

formatdb -p T -l metazoa_20_1_nr.pep.formatdb.log -i metazoa_20_1_nr.pep

 Create an index to quickly acces any sequence in the FASTA file

fastaindex metazoa_20_1_nr.pep metazoa_20_1_nr.index

 Now send to ensembl-admin@ebi.ac.uk and ssg-isg@sanger.ac.uk for farm distribution

7- Prepare files to run blastp
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd -;cd ../blast_in

 Distribute peptide ids in several files. Each of them will contain 100 ids,
 and would correspond to one blastp job.

~/src/ensembl_main/ensembl-compara/scripts/family/SplitPeptides.pl /data/blastdb/Ensembl/family/metazoa_20_1_nr.index

  The created files are named: PeptideSet.1, PeptideSet.2, ..., PeptideSet.n
  so that they are suitable for LSF job array creation. 
 

8- Run blastp with in a LSF jobs array
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For inof on jobs array, see
http://www.sanger.ac.uk/campus/IT/ISG/lsf/job-arrays.shtml

Think about putting out the SEG filter in blastp as we do for homologous genepairs.

 The script used to run individual blastp is
 ensembl-compara/scripts/family/LaunchBlast.pl

 At the beginning of the script, you may need to update few lines that specifie the path
 for the executable to be used

my $blast_executable
my $fastafetch_executable
my $blast_parser_executable


ls|wc -l
      7286

 will tell you how many jobs have to be run. Just have a try with one to make sure everything is ok.

 It is better to place the output files in a different directory to reduce the burden on the filesystem.
 (The fewer files per directory the better).

echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep -fastaindex /data/blastdb/Ensembl/family/metazoa_20_1_nr.index -tab /acari/work7a/abel/family_20_1/srs/metazoa_20_1_nr.tab -dir /acari/work7a/abel/family_20_1/blast_raw/' | bsub -q normal -JFamilyBlastp"[1]" -o ../blast_out/PeptideSet.%I.out

 In this kind of construction the full path of each file/script is needed.
 Check that the BLASTMAT points to /usr/local/ensembl/data/blastmat

 When it is complete, you should get 2 new files

../blast_out/PeptideSet.1.out
../blast_raw/PeptideSet.1.raw.gz

 The first is the STDOUT from LSF. The latter is the blastp output parsed (and zipped)
 in the suitable format needed for the following steps.

 To check if the job finished properly

cd ../blast_out
ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done|awk '{print $2}'|sort |uniq -c

 That gives you the number of jobs "Done" and "Exited" if any.

 Then run the whole lot of jobs

cd ../blast_in
echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep -fastaindex /data/blastdb/Ensembl/family/metazoa_20_1_nr.index -tab /acari/work7a/abel/family_20_1/srs/metazoa_20_1_nr.tab -dir /acari/work7a/abel/family_20_1/blast_raw/' | bsub -q normal -JFamilyBlastp"[2-7286]" -o ../blast_out/PeptideSet.%I.out

 Rerun the failed jobs in ../blast_out.

cd ../blast_out

ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done > ../job_status

grep Exited job_status|sed "s/\./ /g"|awk '{print $2}'|sort -n > job_status.ids

awk 'BEGIN {s=0;e=0;i=0} i==15 {print;i=0} s==0 {s=$1;e=$1;next} $1==e+1 {e=$1;next} $1>e+1 && e==s {printf s",";s=$1;e=$1;i++;next} $1>e+1 && e!=s {printf s"-"e",";s=$1;e=$1;i++;next} END {print s"-"e}' job_status.ids > job_status.ids.collapse

grep Exited job_status |awk '{print $1}'|while read i;do del blast_out/$i;done

cat job_status.ids.collapse|while read i;do echo "echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /data/blastdb/Ensembl/family/metazoa_23_1_nr.pep -fastaindex /data/blastdb/Ensembl/family/metazoa_23_1_nr.index -tab /acari/work7a/abel/family_23_1/srs/metazoa_23_1_nr.tab -dir /acari/work7a/abel/family_23_1/blast_raw/' | bsub -q normal -E \"/acari/work7a/abel/family_23_1/pre_exec\" -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub

The /acari/work7a/abel/family_23_1/pre_exec has to be updated and look like

#!/usr/local/bin/bash

if [ -e /data/blastdb/Ensembl/family/metazoa_23_1.pep ] &&
   [ -e /data/blastdb/Ensembl/family/metazoa_23_1.index ] &&
   [ -e /data/blastdb/Ensembl/family/metazoa_23_1_nr.pep ] &&
   [ -e /data/blastdb/Ensembl/family/metazoa_23_1_nr.index ] &&
   [ -e /data/blastdb/Ensembl/family/metazoa_23_1_nr.pep.psq ] &&
   [ -e /data/blastdb/Ensembl/family/metazoa_23_1_nr.pep.phr ] &&
   [ -e /data/blastdb/Ensembl/family/metazoa_23_1_nr.pep.pin ]; then
 exit 0
else
 exit 1
fi

Then move to blast_in and resubmit the failed jobs

cd blast_in

bash rebsub

9- Build the matrix needed by mcl and check it for symmetry
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../blast_raw

ls|xargs gunzip -c > ../mcl/family_20_1.raw

cd ../mcl

 create a family_20_1.hdr header file,
 The dimensions should be the number of peptides.

cat > family_20_1.hdr
(mclheader
mcltype matrix
dimensions 467417x467417
)

 create asymlink to ../srs/metazoa_20_nr.tab

ln -s ../srs/metazoa_20_1_nr.tab family_20_1.tab

~/src/ensembl_main/ensembl-compara/scripts/family/mcxassemble.sh family_20_1

 This takes about an hour and will generate a family_20_1.sym matrix file. Check the matrix for symmetry

~/src/ensembl_main/ensembl-compara/scripts/family/mcx.sh family_20_1

 The generated family_20_1.sym.check file should look something like that. Nothing should appear after the 'begin', except the closing parenthesis ')'. If not, That means the matrix is not symmetric, which is not good for mcl to run from

(mclheader
mcltype matrix
dimensions 467417x467417
)
(mclmatrix
begin
)

We don't need the raw file anymore and as it takes quite a lot of space, delete it.

rm family_20.raw

10- Run mcl
   ~~~~~~~

This step uses aristotle which has 187Gb of memory :))) and 32 CPUs. As mcl can be multi-threaded, it is very useful.

bsub -C0 -R 'select[ncpus>=16 && mem>5000] rusage[mem=5000]' -q aristotle -n 16 -f "family_20_1.sym > /tmp/family_20_1.sym" -f "family_20_1.mcl < /tmp/family_20_1.mcl" -o mcl.out /nfs/acari/abel/bin/mcl /tmp/family_20_1.sym -I 3.0 -t 16 -P 10000 -S 1000 -R 1200 -pct 90 -do log -o /tmp/family_20_1.mcl

NB: when ever you have finished running mcl (maybe with different parameters), don't forget 
to delete /tmp/family_20_1.* from aristotle /tmp (a shell script having the flavour of 
mcxassemble.sh or mcx.sh could do it automatically...not very useful though if several mcl run 
have to be tested)

To save space,

gzip family_20_1.mcl.gz

11- Load into compara database
    ~~~~~~~~~~~~~~~~~~~~~~~~~

The following step needs to run with an older version of BioPerl (0.7) or with a patched version. 
The Taxon object in more recent versions of bioperl does some excessive validation of species/genus
information that will cause the following to fail.

You'll need a compara database set up, with genome_db, taxon, and method_link tables prefilled. See in
ensembl-compara/sql

NB: This step will load the sequence for ENSEMBLPEP only, not for SWISSPROT or SPTREMBL entries. Those will be loaded in the clustalw step...Should change things here to load them all at once...

Set up a Compara.conf file following the example in 
~/src/ensembl_main/ensembl-compara/modules/Bio/EnsEMBL/Compara/Compara.conf.example

This can take a while, several hours, and you can not do anything else before the loading is completed.

Even though the peptides are already loaded this step still needs to be run as it checks taxon info etc*****Should change this

NB bioperl 0.7 is needed

nohup ~/src/ensembl_main/ensembl-compara/scripts/family/parse_mcl.pl -host ecs2b -port 3306 -dbuser ensadmin -dbpass ensembl -dbname ensembl_compara_20_1 -conf_file Compara.conf family_20_1.mcl.gz family_20_1.tab ../srs/metazoa_20_1.desc.gz ../srs/metazoa_20_1.RedundantIds > family_20_1.description 2> family_20_1.description.err &

Then make sure to load the sequences for SWISSPROT/SPTREMBL loaded in compara.

nohup ~/src/ensembl_main/ensembl-compara/scripts/family/LoadSeqInFamily.pl -host ecs2b -port 3306 -dbuser ensadmin -dbpass ensembl -dbname ensembl_compara_20_1 ../srs/metazoa_20_1.desc.gz /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep > family_20_1.seqload 2>&1 &

12- Generates the family descriptions
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    This part really sucks and need a profound rethinking to get the description more clean and consistant.
       
       ensembl-compara/scritps/family/consensifier.pl 
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       consensifier.pl -d SWISSPROT family_20_1.description > family_20_1.description.SWISSPROT-consensus
       consensifier.pl -d SPTREMBL family_20_1.description > family_20_1.description.SPTREMBL-consensus
       This step takes approx 2 hours total

       ensembl-compara/scripts/family/assemble-consensus.pl
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       assemble-consensus.pl family_20_1.description family_20_1.description.SWISSPROT-consensus \
family_20_1.description.SPTREMBL-consensus  > family_20_1.description-consensus 2> family_20_1.description-consensus.err


update the family description in ensembl_family_20_1 with the data in family_20_1.description-consensus using ensembl-compara/scripts/family/LoadDescriptionInFamily.pl 

LoadDescriptionInFamily.pl -host ecs2d -port 3306 -dbuser ecs2dadmin -dbpass xxxx -dbname ensembl_compara_20_1 family_20_1.description-consensus


13- Run clustalw over all the families
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../clustalw
 
 Just create the number of directory needed by 10000 families and only for those with 2 or more members.
No need to run clustalw on 1 sequence. Let's say that we have 40000 families and only 27152 families
have 2 or more peptide members

mkdir 10000 20000 27152
cd 27152
 
Submit jobs for family_id from 20001 to 27152

echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchClustalwOnFamilies.pl -host ecs2b -port 3306 -dbname ensembl_compara_20_1 -dbuser ensadmin -dbpass xxxx -family_id ${LSB_JOBINDEX} -fasta_file /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep -fasta_index /data/blastdb/Ensembl/family/metazoa_20_1_nr.index -store' | bsub -q small -JFamilyClustalw"[20001-27152]" -o %I.out

NB: For very small families or singletons, the -q small is the right queue to use, as jobs will be extremely quick. For largest families, let's say from family_id 1 to 500 however (where number of members are often > 150), jobs can be longer, and so the -q normal should be used instead of -q small

then the same things 
cd ../20000 for family_id from 10001 to 20000
cd ../10000 for family_id from 1 to 10000

clustalw_mpi
============

For the ~10 biggest families (usually family_id 1 to 10), the number of sequence such that 
the clustalw will never end (i.e. they take a _very_ long time). Kill those jobs that have not completed after 24h.
You will have to run them with the parallelized version of clustalw (that is installed on bc nodes).
As the mpi version is working is rsh command, you want to make sure that you have a ~/.rhosts that contains at least this

+@bc_hosts

and have particular read/write access 

chmod go-rwx ~/.rhosts

So now what to do e.g. for family_id=1

cd ../clustalw_mpi

echo "select m.stable_id from member m, family_member fm where m.member_id=fm.member_id and fm.family_id=1;" |mysql -h ecs4 -P3352 -N -u ensro ensembl_compara_cara_family_21_1 > 1.ids

fastafetch /data/blastdb/Ensembl/family/metazoa_20_1_nr.pep /data/blastdb/Ensembl/family/metazoa_20_1_nr.index 1.ids | grep -v "^Message:" > 1.ids.pep

bsub  -o 1.out -n10 -R"linux span[ptile=2]" ~/src/ensembl_main/ensembl-compara/scripts/family/run_clustalw_mpi.sh 1.ids.pep

NB: span[ptile=2] tells NFS to use 2CPU's per machine 
-n10 tells NFS that you will use 10 CPUs. There is no clear algorithm to choose the right number of CPUs to be used depending on the number of sequences. The more sequences you have the less efficient the mpi implementation is. Guy Coates did some testing

9658 seq 10 CPUs ~14hr
9658 seq 16 CPUs ~13hr
So no much gain from 10 to 16.
1690 seq 10 CPUs ~10min
1690 seq 16 CPUs ~7min

For the largest families we released, I've got that
7015 seq 10 CPUs ~11 hours
4736 seq 10 CPUs  ~5 hours

So as a rule of the thumb, I will recommend
10 CPUs when >=5000 sequences
20 CPUs when <=5000 sequences

Never use over 20 CPUs.

If everything worked fine, you should get 3 additional files, 1.out (the busb output) and 
1.ids.dnd, 1.ids.pep.clw, the clustalw outputs.

To Load the clustalw alignment,
/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchClustalwOnFamilies.pl -host ecs2b -port 3306 -dbname ensembl_compara_20_1 -dbuser ensadmin -dbpass xxxx -family_id 1 -clustal_file 1.ids.pep.clw -store > 1.ids.pep.clw.load 2>&1 &

14- Insert the redundant proteins in the compara db
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following step needs to run with an older version of BioPerl (0.7) or with a patched version. 
The Taxon object in more recent versions of bioperl does some excessive validation of species/genus
information that will cause the following to fail.

cd ../srs

First, set all singletons cigar_line to the length(m.sequence) + "M", because some singletons will disappear with the addition of redundant sequences.

echo "select family_id,count(*) as count from family_member group by family_id having count=1;"|mysql -h ecs2 -u ensro -P3364 ensembl_compara_20_1 |grep -v  family_id |awk '{print "select family_id, length(s.sequence) from member m,family_member fm, sequence s where fm.member_id=m.member_id and fm.family_id="$1" and s.sequence_id = m.sequence_id;"}'|mysql -h ecs2 -u ensro -P3364 ensembl_compara_20_1 |grep -v family_id|awk '{print "update family_member set cigar_line=\""$2"M\" where family_id="$1";"}'|sort -u > update_singletons_cigar_line.sql

mysql -h ecs2 -u ensadmin -pxxxx -P3364 ensembl_compara_20_1 < update_singletons_cigar_line.sql

awk '{for (i=2;i<=NF;i++) print $i}' metazoa_20_1.RedundantIds|fastafetch /data/blastdb/Ensembl/family/metazoa_20_1.pep /data/blastdb/Ensembl/family/metazoa_20_1.index stdin |grep -v "^Message" > metazoa_20_1.RedundantIds.pep

~/src/ensembl_main/ensembl-compara/scripts/family/InsertRedundantInFamilies.pl -host ecs2b -port 3306 -dbname ensembl_compara_20_1 -dbuser ensadmin -dbpass xxxx -conf_file ../mcl/Compara.conf metazoa_20_1.RedundantIds metazoa_20_1.desc.gz metazoa_20_1.RedundantIds.pep > metazoa_20_1.RedundantIds.load.err 2>&1 &

15- Insert the gene stable ids
    ~~~~~~~~~~~~~~~~~~~~~~~~~~

The genome_db table will have to be populated prior to loading the gene stable ids.
See ensembl-compara/sql/UpdatePrefilledTable.pl and ensembl-compara/sql/genome_db
Here is an example of the genome_db table,

mysql> select * from genome_db;
+--------------+----------+-------------------------+----------+------------------+----------+
| genome_db_id | taxon_id | name                    | assembly | assembly_default |Genebuild |
+--------------+----------+-------------------------+----------+------------------+----------+
|            1 |     9606 | Homo sapiens            | NCBI34   |                1 |          |
|            2 |    10090 | Mus musculus            | NCBIM30  |                1 |          |
|            3 |    10116 | Rattus norvegicus       | RGSC3.1  |                1 |          |
|            4 |    31033 | Fugu rubripes           | FUGU2    |                1 |          |
|            5 |     7165 | Anopheles gambiae       | MOZ2A    |                1 |          |
|            6 |     7227 | Drosophila melanogaster | DROM3A   |                1 |          |
|            7 |     6239 | Caenorhabditis elegans  | CEL102   |                1 |          |
|            8 |     6238 | Caenorhabditis briggsae | CBR25    |                1 |          |
|            9 |     7955 | Danio rerio             | ZFISH2   |                1 |          |
+--------------+----------+-------------------------+----------+------------------+----------+
9 rows in set (0.00 sec)

Once the genome_db is loaded, run the following script to load the gene stable ids:

~/src/ensembl_main/ensembl-compara/scripts/family/InsertGenesInFamilies.pl -host ecs2d -port 3306 -dbname ensembl_compara_20_1 -dbuser ecs2dadmin -dbpass xxxx -conf_file ../mcl/Compara.conf > geneLoading 2>&1

16- Run the HealthCheck test suite on the database
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

the test group is 'family_db_constraints'.

Foreign keys db contraints
==========================

taxon_id	PK	taxon
		FK	family_members
		FK	genome_db

family_id	PK	family
		FK	family_members

external_db_id	PK	external_db
		FK	family_members

All ENSEMBLPEP/ENSEMBLGENE taxon_id should have an entry in genome_db**
=====================================================================

mysql> select distinct(taxon_id) from family_members where external_db_id>=3;
+----------+
| taxon_id |
+----------+
|     7165 |
|     6238 |
|     6239 |
|     7227 |
|    10090 |
|     9606 |
|    10116 |
|    31033 |
+----------+

** Need to be added

