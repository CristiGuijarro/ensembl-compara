
1- code API needed and executable

bioperl-live (bioperl-1-2-0?)
ensembl
ensembl-compara

executables
~~~~~~~~~~~
blastall
	using /usr/local/ensembl/bin/blastall
mcl (source can be obtained from http://micans.org/mcl/src/)
	using /nfs/acari/abel/bin/mcxdeblast
	using /nfs/acari/abel/bin/mcxassemble
	using /nfs/acari/abel/bin/mcx
	using /nfs/acari/abel/bin/mcl

2- Choose a working directory with enough disk space
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The family pipeline takes several GB of space (5BG should be sufficient).

mkdir /acari/work7a/abel/family_18_1
cd /acari/work7a/abel/family_18_1
mkdir tmp srs blast_in blast_out blast_raw mcl clustalw clustalw_mpi

3- get the SWISSPROT and SPTREMBL proteins
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd srs

 You will need to have them in SWISSPROT format. We use to get them through SRS

 For SWISSPROT

ssh ice.ebi.ac.uk '/ebi/services/pkgs/srs/bin/osf_5/getz -e -sf swiss "((([libs={swissprot}-Organism: metazoa] ! [libs={swissprot}-Organism: */*]) ! [libs={swissprot}-Organism: *'\''*]) & [libs-SeqLength# 80:])"' |gzip -c > metazoa.swissprot.gz

 For SPTREMBL

ssh ice.ebi.ac.uk '/ebi/services/pkgs/srs/bin/osf_5/getz -e -sf swiss "((([libs={sptrembl}-Organism: metazoa] ! [libs={sptrembl}-Organism: */*]) ! [libs={sptrembl}-Organism: *'\''*]) & [libs-SeqLength# 80:])"' |gzip -c > metazoa.sptrembl.gz

 if you want to know how many sequences you are going to get add the -c option (c for count)

 NB: maybe add in the srs a regexp to take out taxons like 104749, Idiocerinae gen. sp.

4- Format SWISSPROT/SPTREMBL files to get fasta and description file

~/src/ensembl_main/ensembl-compara/scripts/family/GetSeqAndDescription.pl -swiss metazoa.swissprot.gz -sptrembl metazoa.sptrembl.gz -fasta metazoa.pep -desc metazoa.desc > metazoa.err 2>&1 &

The description file looks like

swissprot       128U_DROME      GTP-binding protein 128UP.      taxon_id=7227;taxon_genus=Drosophila;taxon_species=melanogaster;taxon_sub_species=;taxon_common_name=Fruit fly;taxon_classification=melanogaster:Drosophila:Drosophilidae:Ephydroidea:Muscomorpha:Brachycera:Diptera:Endopterygota:Neoptera:Pterygota:Insecta:Hexapoda:Arthropoda:Metazoa:Eukaryota
swissprot       1431_SCHMA      14-3-3 protein homolog 1.       taxon_id=6183;taxon_genus=Schistosoma;taxon_species=mansoni;taxon_sub_species=;taxon_common_name=Blood fluke;taxon_classification=mansoni:Schistosoma:Schistosomatidae:Schistosomatoidea:Strigeidida:Digenea:Trematoda:Platyhelminthes:Metazoa:Eukaryota

5- get the Ensembl peptide predcitions

make sure all Ensembl core database have
a) stable ids (look in tables 'exon_stable_id', 'translation_stable_id', 
               'transcript_stable_id' and 'gene_stable_id')
b) pseudogene flaging (type "pseudogene" may appear in 'gene' table, check with the genebuilder)
c) species data in 'meta' table up to date

If no stable ids are availible, the script will dumped the peptide but with FASTA header having
internal ids...

Generate a list of the core databases on on ecs2d. If some haven't arrived there yet you may have
to add them manually:
mysql -h ecs2d -u ensro -N -B -e 'show databases like "%_core_18_%"' > core_dbs

Modify core_dbs to add assembly type and a prefix name to be used to create the fasta and desc files.
The file should look like that, 3 columns

> more core_dbs
anopheles_gambiae_core_18_2a Ag2
caenorhabditis_briggsae_core_18_25 Cb25
drosophila_melanogaster_core_18_3 Dm3a
fugu_rubripes_core_18_2 Fr2
homo_sapiens_core_18_34 Hs34
rattus_norvegicus_core_18_3a Rn3a

nohup cat core_dbs | awk '!/^#/' | while read i j;do /nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/dumpTranslation.pl -host ecs2d -dbname $i -file $j.pep -taxon_file $j.desc > $j.dump.err 2>&1 ;done > alldumps.err 2>&1 &       

check the peptide numbers you get to see if they are what it is expected. Translation like X+ are not kept in the dumps. 

That will dump a FASTA file with this kind of header
>ENSP00000155093 Transcript:ENST00000155093 Gene:ENSG00000067646 Chr:Y Start:2729728 End:2756029

6- concatenate all fasta and desc files
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cat *.desc | gzip -c > metazoa_18_1.desc.gz
cat *.pep > /data/blastdb/Ensembl/family/metazoa_18_1.pep

 generates the mcl peptides ids index

gunzip -c metazoa_18_1.desc.gz | cut -c-100 |awk -F \t '{print $2}'|sort -u|awk 'BEGIN {idx=0} {print idx,$1;idx++} END {}' > metazoa_18_1.tab


 Do that from an ecs2d node. Not yet, but you'll to send a mail to ensembl-admin@ebi.ac.uk
 and ssg-isg@sanger.ac.uk to ask the distribution of the /data/blastdb/Ensembl/family 
 contains over the farm.

cd /data/blastdb/Ensembl/family/

 Do not forget to delete older version files.
 Format in NCBI blast format

formatdb -p T -l metazoa_18_1.formatdb.log -i metazoa_18_1.pep

 Create an index to quickly acces any sequence in the FASTA file

/nfs/acari/abel/bin/fastaindex metazoa_18_1.pep metazoa_18_1.index

 Now send to ensembl-admin@ebi.ac.uk and ssg-isg@sanger.ac.uk for farm distribution

7- Prepare files to run blastp
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd /acari/work7a/abel/family_18_1/blast_in

 Distribute peptide ids in several files. Each of them will contain 100 ids,
 and would correspond to one blastp job.

gunzip -c ../srs/metazoa_18_1.desc.gz | ~/src/ensembl/ensembl-compara/scripts/family/SplitPeptides.pl

  The created files are named: PeptideSet.1, PeptideSet.2, ..., PeptideSet.n
  so that they are suitable for LSF job array creation. 
 

8- Run blastp with in a LSF jobs array
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

For inof on jobs array, see
http://www.sanger.ac.uk/Users/tjrc/lsf/job-arrays.html

Think about putting out the SEG filter in blastp as we do for homologous genepairs.

 The script used to run individual blastp is
 ensembl-compara/scripts/family/LaunchBlast.pl

 At the beginning of the script, you may need to update few lines that specifie the path
 for the executable to be used

my $blast_executable = "/usr/local/ensembl/bin/blastall";
my $fastafetch_executable = "/nfs/acari/abel/bin/alpha-dec-osf4.0/fastafetch";
$fastafetch_executable = "/nfs/acari/abel/bin/i386/fastafetch";
my $blast_parser_executable = "/nfs/acari/abel/bin/mcxdeblast";

ls|wc -l
      3806

 will tell you how many jobs have to be run. Just have a try with one to make sure everything is ok.

 It is better to place the output files in a different directory to reduce the burden on the filesystem.
 (The fewer files per directory the better).

echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /data/blastdb/Ensembl/family/metazoa_18_1.pep -fastaindex /data/blastdb/Ensembl/family/metazoa_18_1.index -tab /acari/work7a/abel/family_18_1/srs/metazoa_18_1.tab -dir /acari/work7a/abel/family_18_1/blast_raw/' | bsub -q acari -Rncbi -JFamilyBlastp"[1]" -o ../blast_out/PeptideSet.%I.out

 In the kind of construction the full path of each file/script is needed.
 The -Rncbi in the bsub, is there to select machine where the NCBI blast database is accessble locally, basically the ecs and rlx nodes.

 When it is complete, you should get 2 new files

../blast_out/PeptideSet.1.out
../blast_raw/PeptideSet.1.raw.gz

 The first is the STDOUT from LSF. The latter is the blastp output parsed (and zipped)
 in the suitable format needed for the following steps.

 To check if the job finished properly

cd ../blast_out
ls|grep out|while read i;do awk '/^Subject/ && $NF!="Done" {print;exit}' $i;done

 If so you should get no output at all :)

 Then run the whole lot of jobs

cd ../blast_in
echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /data/blastdb/Ensembl/family/metazoa_18_1.pep -fastaindex /data/blastdb/Ensembl/family/metazoa_18_1.pep.index  /acari/work7a/abel/family_18_1/srs/metazoa_18_1.tab -dir /acari/work7a/abel/family_18_1/blast_raw' | bsub -q acari -Rncbi -JFamilyBlastp"[2-3806]" -o ../blast_out/PeptideSet.%I.out

 Rerun the failed jobs. Do not forget to delete the output files .out .err and .blast_tribe.gz

9- Build the matrix needed by mcl and check it for symmetry
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 This step will use parciluar machine, aristotle that have 187Gb of memory :))) and 32 CPUs. As mcl can be multi-threaded, it is very useful.

cd ../blast_raw

ls|xargs gunzip -c > ../mcl/family_18_1.raw

cd ../mcl

 create a family_18.hdr,

cat > family_18.hdr
(mclheader
mcltype matrix
dimensions 467417x467417
)

 create asymlink to ../srs/metazoa_18.tab

ln -s ../srs/metazoa_18_1.tab family_18_1.tab

bsub -q bigmem -Ralpha /nfs/acari/abel/bin/mcxassemble -b family_18_1 -r max

 check if it finished well, if so check the matrix for symmetry

bsub -q bigmem -Ralpha /nfs/acari/abel/bin/mcx /family_18_1.sym lm tp -1 mul add /family_18_1.sym.check wm

 The family_18_1.check should look something like that. Nothing has to appear after the begin,
 but the closin parenthesis, ). If not, That means the matrix is not symmetric, that is not good 
 for mcl to run from

(mclheader
mcltype matrix
dimensions 100x100
)
(mclmatrix
begin
)

gzip family_18.raw

10- Run mcl
   ~~~~~~~

This step will use parciluar machine, aristotle that have 187Gb of memory :))) and 32 CPUs. As mcl can be multi-threaded, it is very useful.

bsub -q acaritest -n 16 -C0 -R"select[mem>=2000] rusage[mem=2000]" -f "family_18_1.sym > /tmp/family_18_1.sym" -f "family_18_1.mcl < /tmp/family_18_1.mcl" -o mcl.out -e mcl.err /nfs/acari/abel/bin/mcl /tmp/family_18_1.sym -I 3.0 -t 16 -P 1000 -R 500 -pct 95 -o /tmp/family_18_1.mcl

NOTE: When setting the number of CPUs to use to 16 LSF seems to multiple the memory requirement by
the number of processors.  Running the above command with -n 16 and 
-R"select[mem>=20000] rusage[mem=20000]" results in the job being stuck in the queue indefinately.
Reducing the memory requirement by 10x to 2000MB seems to solve the problem.  (16*20GB>aristotle's 180GB)

gzip family_18_1.mcl.gz

11- Load in a family database
    ~~~~~~~~~~~~~~~~~~~~~~~~~

The following step needs to run with an older version of BioPerl (0.7) or with a patched version. 
The Taxon object in more recent versions of bioperl does some excessive validation of species/genus
information that will cause the following to fail.

nohup ~/src/ensembl_main/ensembl-compara/scripts/family/parse_mcl.pl -host ecs2b -dbuser ensadmin -dbpass ensembl -dbname ensembl_compara_18_1 family_18_1.mcl family_18_1.tab ../srs/metazoa_18_1.desc.gz > family_18_1.description 2> family_18_1.description.err &

12- Generates the family descriptions
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    This part really sucks and need a profound rethinking to get the description more clean and consistant.
       
       ensembl-compara/scritps/family/consensifier.pl 
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       consensifier.pl -d SWISSPROT mcl_description_18_1 > mcl_description_18_1.SWISSPROT-consensus
       consensifier.pl -d SPTREMBL mcl_description_18_1 > mcl_description_18_1.SPTREMBL-consensus

       ensembl-compara/scripts/family/assemble-consensus.pl
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       assemble-consensus.pl mcl_description_18_1 mcl_description_18_1.SWISSPROT-consensus \
mcl_description_18_1.SPTREMBL-consensus  > families.out 2> families.err


update the family description in ensembl_family_18_1 with the data in families.out using 
ensembl-compara/scripts/family/LoadDescriptionInFamily.pl 

LoadDescriptionInFamily.pl -host ecs2d -dbuser ecs2dadmin -dbpass xxxx -dbname ensembl_family_18_1 families.out


13- Run clustalw over all the families
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 The multiple alignment just need to be run on families with more than one member. In case of
 singletons no need to do so (their sequence is already stored in the database at the parse_mcl stage
 as for all the peptides, but not need to update the cigar_line to NULL, it is already).

cd ../clustalw
 
 Just create the number of directory needed by 10000 families,

mkdir 10000 20000 27152
cd 27152
 
Submit jobs for family_id from 20001 to 27152

echo '/nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchClustalwOnFamilies.pl -host ecs2b -dbname ensembl_compara_18_1 -dbuser ensadmin -dbpass xxxx -family_id ${LSB_JOBINDEX} -fasta_file /data/blastdb/Ensembl/family/metazoa_18_1.pep -fasta_index /data/blastdb/Ensembl/family/metazoa_18_1.pep.index -store' | bsub -q acarichunky -Rncbi -JFamilyClustalw"[20001-27152]" -o %I.out

then the same things 
cd ../20000 for family_id from 10001 to 20000
cd ../10000 for family_id from 1 to 10000

For the ~10 biggest families (usually family_id 1 to 10), the number of sequence is so important that 
the clustalw will never end (i.e. they take a _very_ long time). So kill the jobs just before it is time
 to hand-over the db. 
In the mine time, They would have to be run on the EBI farm that have a parallel mpi clustalw version 
installed. Otherwise, we can let the alignment column NULL for all members of those families.

Make sure to use the acarichunky queue (at least for the small families), as lots of jobs are very short
and make the LSF becomes a bit mad apparently.  
Using the acarichunky queue means that batches of jobs will be run sequentially on a single host in 
order to reduce the overhead of sending jobs to hosts via LSF.  However, for the largest families this
approach is unsuitable (they take several days each to align).  The first 100 or so families should be run
on the normal acari queue and the rest should be run on acarichunky.

14- Insert the gene stable ids
    ~~~~~~~~~~~~~~~~~~~~~~~~~~

The genome_db table will have to be populated prior to loading the gene stable ids.
See ensembl-compara/sql/UpdatePrefilledTable.pl and ensembl-compara/sql/genome_db
Here is an example of the genome_db table,

mysql> select * from genome_db;
+--------------+----------+-------------------------+----------+------------------+
| genome_db_id | taxon_id | name                    | assembly | assembly_default |
+--------------+----------+-------------------------+----------+------------------+
|            1 |     9606 | Homo sapiens            | NCBI34   |                1 |
|            2 |    10090 | Mus musculus            | NCBIM30  |                1 |
|            3 |    10116 | Rattus norvegicus       | RGSC3.1  |                1 |
|            4 |    31033 | Fugu rubripes           | FUGU2    |                1 |
|            5 |     7165 | Anopheles gambiae       | MOZ2A    |                1 |
|            6 |     7227 | Drosophila melanogaster | DROM3A   |                1 |
|            7 |     6239 | Caenorhabditis elegans  | CEL102   |                1 |
|            8 |     6238 | Caenorhabditis briggsae | CBR25    |                1 |
|            9 |     7955 | Danio rerio             | ZFISH2   |                1 |
+--------------+----------+-------------------------+----------+------------------+
9 rows in set (0.00 sec)

Once the genome_db is loaded, run the following script to load the gene stable ids:

~/src/ensembl_main/ensembl-compara/scripts/family/InsertGenesInFamilies.pl -host ecs2d -dbname ensembl_family_18_1 -dbuser ecs2dadmin -dbpass TyhRv -conf_file ~/src/ensembl_main/ensembl-compara/modules/Bio/EnsEMBL/Compara/Compara.conf > ../geneLoading 2>&1

15- Run the HealthCheck test suite on the database
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

the test group is 'family_db_constraints'.

Foreign keys db contraints
==========================

taxon_id	PK	taxon
		FK	family_members
		FK	genome_db

family_id	PK	family
		FK	family_members

external_db_id	PK	external_db
		FK	family_members

All ENSEMBLPEP/ENSEMBLGENE taxon_id should have an entry in genome_db**
=====================================================================

mysql> select distinct(taxon_id) from family_members where external_db_id>=3;
+----------+
| taxon_id |
+----------+
|     7165 |
|     6238 |
|     6239 |
|     7227 |
|    10090 |
|     9606 |
|    10116 |
|    31033 |
+----------+

** Need to be added

