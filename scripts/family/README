
1- code API needed and executable
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

bioperl-live
ensembl
ensembl-compara

executables
~~~~~~~~~~~
blastall
	using /usr/local/ensembl/bin/blastall

mcl (source can be obtained from http://micans.org/mcl/src/)
	using /nfs/acari/avilella/bin/mcxdeblast
	using /nfs/acari/avilella/bin/mcxassemble
	using /nfs/acari/avilella/bin/mcx
	using /nfs/acari/avilella/bin/mcl

2- Choose a working directory with enough disk space
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The family pipeline takes several GB of space (5GB should be sufficient). (df -k)

mkdir -p /lustre/work1/ensembl/avilella/families/family_48
cd /lustre/work1/ensembl/avilella/families/family_48
mkdir tmp fasta blast_in blast_out blast_raw mcl muscle clustalw_mpi

3- Loading in and dumping from compara the peptides
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# The loading of ensembl peptides/genes and uniprot is now done as a common trunk with the gene homology pipeline.
# The loading process will identify redundant proteins using a MySQL index trick and assign to them the same 
# sequence_id. Very clever indeed!

# Before loading, make sure that in each core db:
# a) stable ids are in (look in tables 'exon_stable_id', 'translation_stable_id', 'transcript_stable_id' 
#    and 'gene_stable_id')

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_48" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select * from exon_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from translation_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from transcript_stable_id limit 10"; echo "---"; mysql -hens-staging -uensro $i -N -e "select * from gene_stable_id limit 10"; echo "---"; done | less

# b) species data in 'meta' table up to date

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_48" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select * from meta" | grep species; echo "---"; done | less

# c) check the gene type e.g. pseudogene or RNA that you don't want to load and update the filter out condition if necessary

mysql -hens-staging -uensro -N -e  "show databases" | grep core | grep "\_48" | grep -v expression | while read i; do echo $i; echo "-----"; mysql -hens-staging -uensro $i -N -e "select count(*) as number, biotype from gene group by biotype order by number desc"; echo "---"; done | less

# NB: need to add something here on how to load or a reference to homology documentation

# The dumping is done with ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl script.
# Don't use -noX or nosplit, use the default setting. The dumping process will dump only one version of each sequence,
# so no redundancy is expected in the fasta file.

# Go to the fasta dir
cd fasta

# Takes about 2 minutes
perl ~/src/ensembl_main/ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl -conf /lustre/work1/ensembl/avilella/hive/avilella_compara_homology_48/genetree_all.conf --noredundancy -fasta metazoa_48.pep > metazoa_48.pep.err 2>&1 &

# or if you don't have the hive conf file

perl ~/src/ensembl_main/ensembl-compara/scripts/pipeline/comparaDumpAllPeptides.pl --dbhost compara2 --dbport 3306 --dbuser ensro --dbname avilella_compara_homology_48 --noredundancy --fasta metazoa_48.pep > metazoa_48.pep.err 2>&1 &

grep '>' metazoa_48.pep | wc -l
# 1520968
#v47 1465796

4- Format file for blast
   ~~~~~~~~~~~~~~~~~~~~~

# Takes about 10 seconds
fastaindex metazoa_48.pep metazoa_48.index

# Takes about 5 minutes
formatdb -p T -l metazoa_48.pep.formatdb.log -i metazoa_48.pep

# check metazoa_48.pep.formatdb.log if it is ok delete it

# Formatted 1520968 sequences in volume 0

rm -f metazoa_48.pep.formatdb.log

# Create the index file for future run of mcl

# Takes about 10 seconds
awk 'BEGIN {idx=0} {print idx,$1;idx++}' metazoa_48.index > metazoa_48.tab

5- Prepare files to run blastp
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../blast_in

# Distribute peptide ids in several files. Each of them will contain 100 ids,
# and would correspond to one blastp job.

# Takes about 1 minute
perl ~/src/ensembl_main/ensembl-compara/scripts/family/SplitPeptides.pl -maxids 250 ../fasta/metazoa_48.index

#   The created files are named: PeptideSet.1, PeptideSet.2, ..., PeptideSet.n
#   so that they are suitable for LSF job array creation. 
 

6- Run blastp with in a LSF jobs array
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# For info on jobs array, see
# http://www.sanger.ac.uk/campus/IT/ISG/lsf/job-arrays.shtml
# 
# NB: not done yet, think about putting out the SEG filter in blastp as we do for homologous genepairs, not sure
# that is a good idea. Replace SEG by CAST filtering.
# 
#  The script used to run individual blastp is
#  ensembl-compara/scripts/family/LaunchBlast.pl
# 
#  At the beginning of the script, you may need to update few lines that specifie the path
#  for the executable to be used
# 
# my $blast_executable
# my $fastafetch_executable
# my $blast_parser_executable


ls|wc -l
# 6084
# v47 5864

# will tell you how many jobs have to be run. Just have a try with one to make sure everything is ok.
#
# It is better to place the output files in a different directory to reduce the burden on the filesystem.
# (The fewer files per directory the better).

# LaunchBlast will run like this: system("/usr/local/ensembl/bin/blastall -d $fastadb -i $qy_file -p blastp -e 0.00001 -v 250 -b 0 > $blast_file");
# where:
#   -e  Expectation value (E) [Real]
#   -v  Number of database sequences to show one-line descriptions for (V) [Integer]
#   -b  Number of database sequence to show alignments for (B) [Integer]

echo '/nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.pep -fastaindex /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.index -tab /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.tab -dir /lustre/work1/ensembl/avilella/families/family_48/blast_raw/' | bsub -q long -JFamilyBlastp"[1]" -o ../blast_out/PeptideSet.%I.out

# Check that the BLASTMAT points to /usr/local/ensembl/data/blastmat

echo $BLASTMAT

# When it is complete, you should get 2 new files

../blast_out/PeptideSet.1.out
../blast_raw/PeptideSet.1.raw.gz

# The first is the STDOUT from LSF. The latter is the blastp output parsed (and zipped)
# in the suitable format needed for the following steps.

# To check if the job finished properly

cd ../blast_out
ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done|awk '{print $2}'|sort |uniq -c

# That gives you the number of jobs "Done" and "Exited" if any.

# Then run the whole lot of jobs

# Look for the last PeptideSet.NNNN
ls | awk -F\. '{print $2}' | sort -n | tail

# 6084

cd ../blast_in
echo '/nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.${LSB_JOBINDEX} -fastadb /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.pep -fastaindex /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.index -tab /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.tab -dir /lustre/work1/ensembl/avilella/families/family_48/blast_raw/' | bsub -q long -JFamilyBlastp"[2-6084]" -o ../blast_out/PeptideSet.%I.out

# Rerun the failed jobs in ../blast_out.

cd ../blast_out

ls |while read i;do echo -n $i" ";awk '/^Subject/ {printf $NF" "} /^Job was executed/ {print;exit}' $i;done > ../job_status

grep Exited ../job_status|sed "s/\./ /g"|awk '{print $2}'|sort -n > ../job_status.ids

awk 'BEGIN {s=0;e=0;i=0} i==15 {print;i=0} s==0 {s=$1;e=$1;next} $1==e+1 {e=$1;next} $1>e+1 && e==s {printf s",";s=$1;e=$1;i++;next} $1>e+1 && e!=s {printf s"-"e",";s=$1;e=$1;i++;next} END {print s"-"e}' ../job_status.ids > ../job_status.ids.collapse

cd ..

grep Exited job_status |awk '{print $1}'|while read i;do rm -f blast_out/$i;done

cat job_status.ids.collapse|while read i;do echo "echo '/nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchBlast.pl -idqy PeptideSet.\${LSB_JOBINDEX} -fastadb /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.pep -fastaindex /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.index -tab /lustre/work1/ensembl/avilella/families/family_48/fasta/metazoa_48.tab -dir /lustre/work1/ensembl/avilella/families/family_48/blast_raw/' | bsub -q long -JFamilyBlastp\"["$i"]\" -o ../blast_out/PeptideSet.%I.out";echo;done > blast_in/rebsub

# Then move to blast_in and resubmit the failed jobs

cd blast_in

bash rebsub

8- Build the matrix needed by mcl and check it for symmetry
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../blast_raw

# Takes about 8-10 minutes, do on a farm node
bsub 'ls|xargs gunzip -c > ../mcl/family_48.raw'

cd ../mcl

# create a symlink to ../fasta/metazoa_48.tab

ln -s ../fasta/metazoa_48.tab family_48.tab

# create a family_48.hdr header file,
# The dimensions should be the number of peptides. That can be obtained by

wc -l family_48.tab

# 1520968 family_48.tab


cat > family_48.hdr
(mclheader
mcltype matrix
dimensions 1520968x1520968
)

# This takes not 30 min but about 8-10 minutes now that we have bigmem
# fast nodes, and will generate a family_48.bin matrix file.
bsub '~/src/ensembl_main/ensembl-compara/scripts/family/mcxassemble.sh family_48'

# Check that everything is all right in family_48.mcxassemble.err

# We don't need the raw file anymore and as it takes quite a lot of space, delete it.

rm -f family_48.raw

9- Run mcl
   ~~~~~~~

This step uses turing which has 192Gb of memory :))) and 16 CPUs. As mcl can be multi-threaded, it is very useful.

# Takes about 5 hours
bsub -C0 -R 'select[ncpus>=8 && mem>14000 && type==IA64] rusage[mem=14000] span[hosts=1]' -q hugemem -n 8 -f "family_48.bin > /tmp/family_48.bin" -f "family_48.mcl < /tmp/family_48.mcl" -o mcl.out /nfs/acari/avilella/bin/arch-ia64/mcl /tmp/family_48.bin -I 2.1 -t 8 -P 10000 -S 1000 -R 1260 -pct 90 -o /tmp/family_48.mcl

# NB: whenever you have finished running mcl (maybe with different parameters), don't forget 
# to delete /tmp/family_48.* from aristotle /tmp (a shell script having the flavour of 
# mcxassemble.sh or mcx.sh could do it automatically...not very useful though if several mcl run have to be tested)

10- Load into compara database
    ~~~~~~~~~~~~~~~~~~~~~~~~~

# You'll need a compara database set up, with genome_db, taxon, and method_link tables prefilled.

# Edit the reg_conf.48.pl to point to the compara_homology db
/lustre/work1/ensembl/avilella/families/family_48/mcl/reg_conf.48.pl

# Your reg_conf.pl should be something like

use strict;
use Bio::EnsEMBL::Utils::ConfigRegistry;
use Bio::EnsEMBL::Compara::DBSQL::DBAdaptor;

new Bio::EnsEMBL::Compara::DBSQL::DBAdaptor(-host => 'compara2',
                                            -user => 'xxxxx',
                                            -pass => 'xxxxxx',
                                            -port => 3306,
                                            -species => 'compara48',
                                            -dbname => 'avilella_compara_homology_48');
1;

# This takes around an hour, and you can not do anything else before the loading is completed.

nohup ~/src/ensembl_main/ensembl-compara/scripts/family/parse_mcl.pl --dbname compara48 --reg_conf /lustre/work1/ensembl/avilella/families/family_48/mcl/reg_conf.48.pl family_48.tab family_48.mcl > family_48.description 2> family_48.description.err &

# To save space,

bsub 'gzip family_48.mcl'

11- Run muscle or clustalw over all the families
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# !!!Step 13 should be run also at the same time. It is not dependant on multiple alignments.

# Scratch is better than work here
mkdir -p /lustre/scratch1/ensembl/avilella/families/family_48/muscle
cd /lustre/scratch1/ensembl/avilella/families/family_48/muscle

The old way of doing this was to create a job per alignment, with the
small ones being in the short queue and the longer ones going to the
normal queue. This system was always painful for the farm, and systems
asked us to do better.

In the middle of v48 production I created a
LaunchMuscleOnFamilies_batch.pl script which will run 'num_families'
in the same job, starting from 'starting_family_id':

mysql -hcompara2 -uensro avilella_compara_homology_48 -e "select count(*), family_id from family_member group by family_id having count(*)>1" | wc -l
44852
# v47 43834

bsub -q normal 'perl /nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchMuscleOnFamilies_batch.pl -host compara2 -port 3306 -dbname avilella_compara_homology_48 -dbuser ensadmin -dbpass xxxx -starting_family_id 42835 -num_families 835' -o ../42835.out -e ../42835.err

We put the logs for this in the scratch1 directory instead of the work1 directory,

/lustre/scratch1/ensembl/avilella/families/family_48/muscle

Right now we allocate the alignments manually, and keep the logs in subdirectories.

So for the ~20000 smallest alignments, do something like:

export range=100
perl ~/src/ensembl_main/ensembl-compara/scripts/family/get_nums.pl -start 20000 -end 44852 -range $range

which gives the starting_family_id from 20000 to 44852 in batches of 100. Then apply (change dbpass!):

starts="20001 20101 20201 20301 20401 20501 20601 20701 20801 20901 21001 21101 21201 21301 21401 21501 21601 21701 21801 21901 22001 22101 22201 22301 22401 22501 22601 22701 22801 22901 23001 23101 23201 23301 23401 23501 23601 23701 23801 23901 24001 24101 24201 24301 24401 24501 24601 24701 24801 24901 25001 25101 25201 25301 25401 25501 25601 25701 25801 25901 26001 26101 26201 26301 26401 26501 26601 26701 26801 26901 27001 27101 27201 27301 27401 27501 27601 27701 27801 27901 28001 28101 28201 28301 28401 28501 28601 28701 28801 28901 29001 29101 29201 29301 29401 29501 29601 29701 29801 29901 30001 30101 30201 30301 30401 30501 30601 30701 30801 30901 31001 31101 31201 31301 31401 31501 31601 31701 31801 31901 32001 32101 32201 32301 32401 32501 32601 32701 32801 32901 33001 33101 33201 33301 33401 33501 33601 33701 33801 33901 34001 34101 34201 34301 34401 34501 34601 34701 34801 34901 35001 35101 35201 35301 35401 35501 35601 35701 35801 35901 36001 36101 36201 36301 36401 36501 36601 36701 36801 36901 37001 37101 37201 37301 37401 37501 37601 37701 37801 37901 38001 38101 38201 38301 38401 38501 38601 38701 38801 38901 39001 39101 39201 39301 39401 39501 39601 39701 39801 39901 40001 40101 40201 40301 40401 40501 40601 40701 40801 40901 41001 41101 41201 41301 41401 41501 41601 41701 41801 41901 42001 42101 42201 42301 42401 42501 42601 42701 42801 42901 43001 43101 43201 43301 43401 43501 43601 43701 43801 43901 44001 44101 44201 44301 44401 44501 44601 44701 44801 44852"
for start in $starts
do
        mkdir $start
        cd $start
        bsub -o $start.out -e $start.err -q normal "perl /nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchMuscleOnFamilies_batch.pl -host compara2 -port 3306 -dbname avilella_compara_homology_47 -dbuser ensadmin -dbpass xxxx -starting_family_id $start -num_families $range -store"
        cd ..
        sleep 0.1
done

Once the previous batch is in the final stages in terms of mysql query
load in the db, then proceed with the next batch is 2000 to 5000 in
batches of 100:

export range=100
perl ~/src/ensembl_main/ensembl-compara/scripts/family/get_nums.pl -start 5000 -end 20000 -range $range

Then the next with a batch size 20:

export range=20
perl ~/src/ensembl_main/ensembl-compara/scripts/family/get_nums.pl -start 1000 -end 5000 -range $range

using more memory

-R 'select[mem>1500] rusage[mem=1500]'

Then the next with a batch size of 10:

export range=10
perl ~/src/ensembl_main/ensembl-compara/scripts/family/get_nums.pl -start 500 -end 1000 -range $range

using even more memory

-R 'select[mem>3500] rusage[mem=3500]'

Then the next with a batch size of 5:

export range=5
perl ~/src/ensembl_main/ensembl-compara/scripts/family/get_nums.pl -start 50 -end 500 -range $range

-R 'select[mem>7000] rusage[mem=7000]'

Then all the rest but the two biggest with a batch size of 2:

perl ~/src/ensembl_main/ensembl-compara/scripts/family/get_nums.pl -start 2 -end 50 -range 2

in the long queue and 7000 memory

-q long -R 'select[mem>7000] rusage[mem=7000]'

The two biggest families tend to be too big, so try with muscle then with clustalw:

bsub -q long -o 2.out -e 2.err  -R 'select[mem>15000] rusage[mem=15000]' -M3000000 'perl /nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchMuscleOnFamilies.pl -host compara2 -port 3306 -dbname avilella_compara_homology_48 -dbuser ensadmin -dbpass xxxx -family_id 2 -store -fast'

bsub -q long -o 1.out -e 1.err  -R 'select[mem>15000] rusage[mem=15000]' -M3000000 'perl /nfs/acari/abel/src/ensembl_main/ensembl-compara/scripts/family/LaunchMuscleOnFamilies.pl -host compara2 -port 3306 -dbname avilella_compara_homology_48 -dbuser ensadmin -dbpass xxxx -family_id 1 -store -fast'

At any point one can check what is undone, what is ongoing, and hence what is missing by looking at the NULLs in the cigar_lines for family_member:

export TIMESTAMP=`date +2%3y%m%d_%H%M%S` && bjobs -l | grep family_id | awk -Fd '{print $2}' | awk '{print $1}' | sort -n | uniq > ongoing.$TIMESTAMP; mysql -hcompara2 -uensro avilella_compara_homology_48 -N -e "select distinct(family_id) from family_member where cigar_line IS NULL and family_id<43835" > undone.families.$TIMESTAMP && join -v 1 undone.families.$TIMESTAMP ongoing.$TIMESTAMP; echo "="; wc -l undone.families.$TIMESTAMP

Making a head or a tail of the undon.families.$TIMESTAMP, we can resubmit them to Muscle with the -fast option, or to clustalw instead:

cd failed

head -n 100 undone.families.$TIMESTAMP > big.undone.list
tail -n 100 undone.families.$TIMESTAMP > small.undone.list

cat big.undone.list | while read i; do bsub -o $i.out -e $i.err -q long  -R 'select[mem>3500] rusage[mem=3500]' -M3500000 "perl /nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchClustalwOnFamilies.pl -host compara2 -port 3306 -dbname avilella_compara_homology_48 -dbuser ensadmin -dbpass ensembl -family_id $i -store"; sleep 0.1; done

**

When the alignments fail with muscle, we resort to clustalw:

The same kind of script but running CLUSTALW also exists, ensembl-compara/scripts/family/LaunchMuscleOnFamilies.pl

And if then again it does not work, run clustalw_mpi (see below).

clustalw_mpi
============

In cases of big families that did not finish with muscle or single-cpu clustalw, you can start clustal_mpi runs while letting
their muscle/single-cpu clustalw jobs running.
mpi_clustalw is a parallelized version of clustalw (that is installed on bc nodes).
As the mpi version is working is rsh command, you want to make sure that you have a ~/.rhosts that contains at least this

+@bc_hosts

and have particular read/write access 

chmod go-rwx ~/.rhosts

So now what to do e.g. for family_id=1

cd ../clustalw_mpi

mysql -h compara2 -P3306 -N -u ensro -e "select m.stable_id from member m, family_member fm where m.member_id=fm.member_id and fm.family_id=1" avilella_compara_homology_47 > 1.ids

fastafetch /lustre/work1/ensembl/avilella/families/family_47/fasta/metazoa_47.pep /lustre/work1/ensembl/avilella/families/family_47/fasta/metazoa_47.index -F true 1.ids > 1.ids.pep

bsub  -o 1.out -n10 -R"linux span[ptile=2]" ~/src/ensembl_main/ensembl-compara/scripts/family/run_clustalw_mpi.sh 1.ids.pep

NB: span[ptile=2] tells NFS to use 2CPU's per machine 
-n10 tells NFS that you will use 10 CPUs. There is no clear algorithm to choose the right number of CPUs to be used depending on the number of sequences. The more sequences you have the less efficient the mpi implementation is. Guy Coates did some testing

9658 seq 10 CPUs ~14hr
9658 seq 16 CPUs ~13hr
So no much gain from 10 to 16.
1690 seq 10 CPUs ~10min
1690 seq 16 CPUs ~7min

For the largest families we released, I've got that
7015 seq 10 CPUs ~11 hours
4736 seq 10 CPUs  ~5 hours

So as a rule of the thumb, I will recommend
10 CPUs when >=5000 sequences
20 CPUs when <=5000 sequences

Never use over 20 CPUs.

If everything worked fine, you should get 3 additional files, 1.out (the busb output) and 
1.ids.dnd, 1.ids.pep.clw, the clustalw outputs.

To Load the clustalw alignment, first check that the  muscle/single-cpu clustal job did not finish properly (if so
you're done with this family), if not bkill it before loading.
/nfs/acari/avilella/src/ensembl_main/ensembl-compara/scripts/family/LaunchClustalwOnFamilies.pl -host compara2 -port 3306 -dbname avilella_compara_homology_45 -dbuser ensadmin -dbpass xxxx -family_id 1 -clustal_file 1.ids.pep.clw -store > 1.ids.pep.clw.load 2>&1 &

12- Insert the redundant proteins in the compara db
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd ../fasta

First, set all singletons cigar_line to the length(m.sequence) + "M", because some singletons will disappear with the addition of redundant sequences.

mysql -h compara2 -u ensro -P3306 -N -e "select family_id,count(*) as count from family_member group by family_id having count=1" avilella_compara_homology_48 | awk '{print "select family_id, length(s.sequence) from member m,family_member fm, sequence s where fm.member_id=m.member_id and fm.family_id="$1" and s.sequence_id = m.sequence_id;"}'|mysql -h compara2 -u ensro -P3306 -N avilella_compara_homology_48 |awk '{print "update family_member set cigar_line=\""$2"M\" where family_id="$1";"}'|sort -u > update_singletons_cigar_line.sql

mysql -h compara2 -u ensadmin -pxxxx -P3306 avilella_compara_homology_48 < update_singletons_cigar_line.sql

perl ~/src/ensembl_main/ensembl-compara/scripts/family/InsertRedundantPeptidesAndGenesInFamilies.pl --reg_conf /lustre/work1/ensembl/avilella/families/family_48/mcl/reg_conf.48.pl --dbname compara48 > Redundancy_and_Genes_load.err 2>&1 &

IMPORTANT: add healthcheck about NULL cigar_line
mysql -hcompara2 -uensro avilella_compara_homology_48 -e "select m.source_name,count(*) from family_member fm, member m where fm.member_id=m.member_id and fm.cigar_line="NULL" group by m.source_name"

This should return count 0;

mysql -hcompara2 -uensro avilella_compara_homology_48 -e "select fm.family_id,count(*) from family_member fm, member m where fm.member_id=m.member_id and fm.cigar_line is NULL and m.source_name!='ENSEMBLGENE' group by fm.family_id"

This should only list the families for which multiple alignment could not be run.
+-----------+----------+
| family_id | count(*) |
+-----------+----------+
|         1 |    15115 |
|        29 |     1714 |
|       176 |      769 |
+-----------+----------+

13- Generates the family descriptions
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    This part really sucks and need a profound rethinking to get the description more clean and consistant.

       ensembl-compara/scripts/family/consensifier.pl 
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       # This step takes approx 2 hours total
       cd mcl
       perl ~/src/ensembl_main/ensembl-compara/scripts/family/consensifier.pl -d "Uniprot/SWISSPROT" family_48.description > family_48.description.SWISSPROT-consensus 2> family_48.description.SWISSPROT-consensus.err
       perl ~/src/ensembl_main/ensembl-compara/scripts/family/consensifier.pl -d "Uniprot/SPTREMBL" family_48.description > family_48.description.SPTREMBL-consensus 2> family_48.description.SPTREMBL-consensus.err

       ensembl-compara/scripts/family/assemble-consensus.pl
       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       perl ~/src/ensembl_main/ensembl-compara/scripts/family/assemble-consensus.pl family_48.description family_48.description.SWISSPROT-consensus family_48.description.SPTREMBL-consensus  > family_48.description-consensus 2> family_48.description-consensus.err


update the family description in ensembl_family_48 with the data in family_48.description-consensus using ensembl-compara/scripts/family/LoadDescriptionInFamily.pl 
Use the same reg_cong.pl as in step 11

perl ~/src/ensembl_main/ensembl-compara/scripts/family/LoadDescriptionInFamily.pl --reg_conf /lustre/work1/ensembl/avilella/families/family_48/mcl/reg_conf.48.pl --dbname compara48 family_48.description-consensus


