README for running translated BLAT	

At the moment the working directories are in /ecs4/work2/ensembl/cara/

Summary:


mkdir for DNA for both species
Dump DNA for both species.
	 At the moment the database species (eg human) and the query species (eg Fugu) are both dumped in chunks of 100000 with an overlap of 1000 in softmasked mode). The query database should be in a single fasta file whilst the db species tends to be in seperate chromosome fasta files, as this makes it easier to run on the farm. 

Make indices for query
Make ID dir and files for query

mkdir for BLAT run
mkdir for db chromosomes
Run BLAT across farm
	The test of running the first Id file against all db chromosomes also allows for the ooc file to be created ( holds info on db 5mers which occur too often for BLAT) If this hasn\'t finished running before the rest of the BLATs are sent off they will fall over.
	
check jobs and rerun any failures

grep the results lines out into '.raw' files

run the parser to get rid of overlapped hsps to create '.data' and '.tbf' files

run stats progs to check data



Details:

NB lines beginning with $ are command lines
example used will be chicken against human

$ cd /ecs4/work2/ensembl/cara/DNAFA/TX/
$ mkdir Gg1 Hs35

$cd Gg1

get chromosome names for chicken 

$ echo " select sr.name, cs.name from coord_system cs, seq_region sr, seq_region_attrib sra, attrib_type at where sra.attrib_type_id=at.attrib_type_id and at.code='toplevel' and sr.seq_region_id=sra.seq_region_id and sr.coord_system_id=cs.coord_system_id and sr.name not like \"%_NT_%\" and sr.name not like \"%_DR_%\" and sr.name not like \"UNKN\";" | mysql -h ecs2 -u ensro -P 3364 gallus_gallus_core_20_1 | awk '!/name/' | sort -u > Gg1_chr_names

(as this is rather long there is a script in /ensembl_compara/misc_scripts dir which may be used called: get_PH_chrs_20.sh)

Dump chicken DNA

$ cat Gg1_chr_names | while read i ; do  bsub -q normal -o $i.out   ~/src/ensembl_main/ensembl-compara/scripts/dumps/DumpChromosomeFragments.pl -host ecs2 -port 3364 -dbuser ensro -dbname gallus_gallus_core_20_1 -chr_names $i -overlap 1000 -chunk_size 100000 -masked 2 -phusion Gg -o $i.fa; done

Check that all has run correctly with

$ cat Gg1_chr_names | while read i ; do echo "doing $i " ; ls | grep out| wc -l ; echo -n "Done: " ; ls |grep out | xargs grep Done | wc -l ; echo  "Exit: " ; ls |grep out | xargs grep Exit ; done

This will count the number of out files, the number of Dones (succesfully completed, LSF can get flakey and loose jobs and so rerun them, shouldn\'t be a problem as '.fa' file should be overwritten , but should check anyway) and prints any that exited
Repeat any which failed


Dump for Human as above 


For query species (if to be used as a db species later may be kept in seperate chromosomes and the scripts changed accordingly)

$ cat *.fa > Gg1.fa_all

$ rm -f *fa  
$ mv Gg1.fa_all Gg1.fa

Make ID files for query species in dir DNAFA/TX/Gg1

$ fastaindex -f Gg1.fa -i Gg1.fa.index
$ mkdir Gg1Ids
$ grep ">" Gg1.fa | sed "s/>//" | cut -c-100 | awk 'BEGIN {ind=1; size=40} size>0 {print Gg1,ind; size--; next} size==0 {ind++;size=40;print Gg1, ind; size--}END{}'|while read i j; do echo $i >>Gg1Ids/Gg1Ids.$j; done


To run BLAT

$ cd ../../../BLAT/
$ mkdir Gg1Hs35
$ cd Gg1Hs35

$ cp ../../DNAFA/TX/Hs35/Hs35_chr_names ./

Find out how many jobs to run: 
$ ls ../../DNAFA/TX/Gg1/Gg1Ids/ | wc -l


NB At the moment the output comes from a print statement in Blat --- which isn\'t good 


As many jobs are involved its best to run these without nfs using the Run_LaunchBLAT.sh script which is as follows:


cat Hs35_chr_nmaes | while read i; do 
bsub -q normal -J"Gg1Hs35_$i\[1]" -o Hs35_$i/bsout.Gg1Hs35.$i.%I <<EOF
. /usr/local/lsf/conf/profile.lsf
/ecs4/work2/ensembl/cara/BLAT/LaunchBLAT.pl \
-idqy /ecs4/work2/ensembl/cara/DNAFA/TX/Gg1/Gg1Ids/Gg1Ids.\${LSB_JOBINDEX} \
-fastaqy /ecs4/work2/ensembl/cara/DNAFA/TX/Gg1/Gg1.fa \
-indexqy /ecs4/work2/ensembl/cara/DNAFA/TX/Gg1/Gg1.fa.index \
-fastadb /ecs4/work2/ensembl/cara/DNAFA/TX/Hs35/$i.fa \
-query_type dnax -target_type dnax  -makefile Hs35_$i/5.ooc \
2> /tmp/err.Gg1Hs35.\${LSB_JOBINDEX}.$i.\$\$ 
status=\$?
set -e 
lsrcp /tmp/err.Gg1Hs35.\${LSB_JOBINDEX}.$i.\$\$ ecs4b:$PWD/Hs35_$i/Gg1Hs35.\${LSB_JOBINDEX}.$i.err
/bin/rm -f /tmp/err.Gg1Hs35.\${LSB_JOBINDEX}.$i.\$\$ 
exit \$status
EOF
done

#NB  the STDout isn't stored in this case include "> out " etc if need to collect it -- don't forget to remove it


Check everything ran ok and run with the rest 2-x where x is the number of id files

Check everything ran ok. Should run overnight but can take as long as 3 days depending on the load on the farm, and whether the chickens have been fed recently.


$ cat Hs35_chr_names | while read i ; do cd Hs35_$i ; echo "doing Hs35_$i " ; echo "errors: "; ls | grep err| xargs grep rror ; echo -n out ; l | grep out | wc -l; echo -n err ; l | grep err | wc -l; echo -n Done ; l | grep out | xargs grep Done |wc -l ; echo -n "cant open" ; l | grep err | xargs grep "Can\'t open" | wc  -l ; l | grep out |xargs grep Exit; cd ../; done

There should be the same number of files as there were jobs -- ie the number of id files

Any failures need to be deleted and rerun. 


grep out reults lines


$ cat Hs35_chr_names | while read i ; do cd Hs35_$i ; echo "doing Hs35_$i " ; ls | grep err | xargs grep -h Gg >> ../Gg1Hs35_$i\.raw ; cd ../ ; done

parse these files to remove overlapped hsps

$ cat Hs35_chr_names | while read i ; do  echo "/nfs/acari/cara/src/ensembl_main/ensembl-compara/scripts/BLAT/parse_and_score.pl -F Gg1Hs35_$i\.raw -O Gg1Hs35_$i -D 15000 -S1 Gg -S2 Hs -CF /nfs/acari/cara/.Registry.conf "  | bsub -q normal -o Gg1Hs35_$i\.out;; done

Check these all ran ok 
cat Hs35_chr_names | while read i ; do echo $i ; grep Lost Gg1Hs35_$i.out ; done

Then load into db. The easiest way to do this is to create tab files and then load these manually. But be warned that the method_link_species_set table gets filled in which can cause problems if the files are not loaded later.

 cat all the data files into one file. 
 cat Gg1Hs35_*.data >>Gg1Hs35.data
 
/nfs/acari/cara/src/ensembl_main/ensembl-compara/scripts/BLAT/LoadBLATAlignments.pl -dbname cara_ensembl_compara_27_1 -cs_genome_db_id 1 -qy_genome_db_id 11 -file Gg1Hs35.data -alignment_type TRANSLATED_BLAT -conf_file  /nfs/acari/cara/.Registry.conf  -tab 1

if loading directly then leave off "-tab 0"


This will produce the following files 

genomic_align_block.Gg1Hs35.data
genomic_align.Gg1Hs35.data
genomic_align_group.Gg1Hs35.data

logon to the machine that has the db on it. (eg. caa-stat mysql_3364 on ecs2 will tell you which machine ecs2:3364 is currently on). These are loaded into the db using :

mysql -S /mysql/data_3364/mysql_3364.sock -u ensadmin -Pxxxxxxx 

mysql> use cara_ensembl_compara_27_1 ;

database changed

mysql> load data infile /ecs2/scratch3/cara/BLAT/Gg1Hs35/genomic_align_block.Gg1Hs35.data into table genomic_align_block ;

repeat for the other two files and you're done!




