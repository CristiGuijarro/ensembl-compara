ABOUT
~~~~~

This document describes how to run the ensembl-compara genetree
pipeline.

- Loads the longest peptide for each gene loci in each configured
  species database into the compara DB's member table.

- Loads each UniProt protein into the member table (metazoa only for
  now). Only needed if the family pipeline is to be run subsequently.

- Performs all-against-all blastp searched of the member proteins in
  the DB.

- Run PAFCluster to create the clusters of proteins.

- Run Muscle to obtain the protein multialignments for each cluster.

- Run NJTREE_PHYML with a given species tree to create the protein trees.

- Run OrthoTree to create the homology relationships per each genepair
in the tree.

- BreakPAFCluster will run with increased BSR (+0.1) in case Muscle or
  NJTREE_PHYML fail on big trees or complicated alignments and create
  new jobs for the subclusters that creates.

- Provided that the species are close enough, the pipeline can also
  run a dN/dS analysis for the orthologs of pairs of species, in the
  Homology_dNdS analysis. This step is optional.

The genetree process overlaps initially with the homology pipeline,
but once the clusters are created, it differs in the way things are
done. Read README-homology for more information.


1- code API needed and executable
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  bioperl-live (bioperl-1-2-3)
  bioperl-run (1.4) for the CodeML runnable/parser
  ensembl
  ensembl-compara
  ensembl-hive
  ensembl-analysis
  ensembl-pipeline

  executables
  ~~~~~~~~~~~
  wublastp
      using /usr/local/ensembl/bin/wublastp
  setdb
      using /usr/local/ensembl/bin/setdb
  muscle
      using /usr/local/ensembl/bin/muscle
  njtree
      using /lustre/work1/ensembl/avilella/bin/i386/njtree_gcc
  codeml
      using /usr/local/ensembl/bin/codeml

1.2 Code checkout

bioperl code;

  $ cvs -d :ext:bio.perl.org:/home/repository/bioperl \
    co -r branch-1-2-3 bioperl-live

bioperl-run code (for the CodeML runnable/parser)
  
  $ cvs -d :ext:bio.perl.org:/home/repository/bioperl \
    co -r bioperl-run-release-1-4-0 bioperl-run

core ensembl code

  $ cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co ensembl

ensembl-compara code (for Compara API and schema)

  $ cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co ensembl-compara

ensembl-analysis code (for Runnables)

  $ cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co ensembl-analysis

ensembl-pipeline code (for Pipeline)

  $ cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co ensembl-pipeline

ensembl-hive code

  $ cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co  ensembl-hive


1.3 Perl environment

in tcsh
  $ setenv BASEDIR   /some/path/to/modules
  $ setenv PERL5LIB ${BASEDIR}/ensembl/modules:${PERL5LIB}
  $ setenv PERL5LIB ${BASEDIR}/ensembl-compara/modules:${PERL5LIB}
  $ setenv PERL5LIB ${BASEDIR}/ensembl-pipeline/modules:${PERL5LIB}
  $ setenv PERL5LIB ${BASEDIR}/ensembl-analysis/modules:${PERL5LIB}
  $ setenv PERL5LIB ${BASEDIR}/ensembl-hive/modules:${PERL5LIB}
  $ setenv PERL5LIB ${BASEDIR}/bioperl-live:${PERL5LIB}
  $ setenv PERL5LIB ${BASEDIR}/bioperl-run:${PERL5LIB}

in bash
  $ BASEDIR=/some/path/to/modules
  $ export PERL5LIB=${BASEDIR}/ensembl/modules:${PERL5LIB}
  $ export PERL5LIB=${BASEDIR}/ensembl-compara/modules:${PERL5LIB}
  $ export PERL5LIB=${BASEDIR}/ensembl-pipeline/modules:${PERL5LIB}
  $ export PERL5LIB=${BASEDIR}/ensembl-analysis/modules:${PERL5LIB}
  $ export PERL5LIB=${BASEDIR}/ensembl-hive/modules:${PERL5LIB}
  $ export PERL5LIB=${BASEDIR}/bioperl-live:${PERL5LIB}
  $ export PERL5LIB=${BASEDIR}/bioperl-run:${PERL5LIB}


1.4 CPAN Perl modules
  www.cpan.org

  DBI
  DBD::mysql
  Data::UUID
  Statistics::Descriptive


2- Create the tables in the database
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
These tables are already in the main ensembl-compara/sql/table.sql
file as of ensembl v40.

Pick a mysql instance and create a database;

  $ set COMPARA_DBNAME=${USER}_ensembl_compara_48
  $ mysql -e "create database $COMPARA_DBNAME"

And load the schemas;

  $ cat $BASEDIR/ensembl-hive/sql/tables.sql \
        $BASEDIR/ensembl-compara/sql/table.sql \
        $BASEDIR/ensembl-compara/sql/pipeline-tables.sql \
    | mysql $COMPARA_DBNAME

3- Load the NCBI taxonomy data 
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You now need to load the NCBI taxonomy data into the ncbi_taxa_name
and ncbi_taxa_node tables. See the following file;

  $BASEDIR/ensembl-compara/scripts/taxonomy/README-taxonomy

You may alternatively be able to copy taxonomy tables from an existing
compara db (this may take a few mins), e.g.

  $ mysqldump --no-create-info ensembl_compara_old \
    ncbi_taxa_node ncbi_taxa_name \
    | mysql $COMPARA_DBNAME

Or, (Ensembl-site-specific)

  $ mysqldump -u ensro -h ens-livemirror \
    --extended-insert --compress --delayed-insert \
    ncbi_taxonomy ncbi_taxa_node ncbi_taxa_name \
    | mysql $COMPARA_DBNAME


4- compara-hive config file
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Copy and modify the compara-hive config file
   
  $ cd $BASEDIR/ensembl-compara/scripts/pipeline
  $ cp compara-hive-genetree.conf.example my_compara.conf
  <editor> my_compara.conf

You may need to change the database names, port, dbnames, and the
paths to the 'hive_output_dir' and 'fasta_dir'. Note that these dirs
must exist.

You can enable/disable various components of the system
(e.g. MCL-clustering, dNdS) where indicated depending on your
preferences.

IMPORTANT: The hive system can generate an awful lot of log outputs
that are dumped in the hive_output_dir. When a pipeline runs fine,
these are not needed and can take a lot of disk space as well as
generate a large number of files. If you don't want log outputs
(recommended), then just don't specify any hive_output_dir.


4.1- Species Configuration
     ----------

Connection parameters to the source ensembl core should be configured
in this file.

Some 'gotchas' with the core databases should be checked;

- The top-level coordinate system must include a version,
  mysql> SELECT name, version FROM coord_system ORDER BY rank LIMIT 1;

- There must be a genebuild.version set in the meta table,
  mysql> SELECT * FROM meta WHERE meta_key="genebuild.version";

- Only genes on slices marked as 'toplevel' will be included.
  mysql> SELECT count(*) 
         FROM seq_region cs, seq_region_attrib a, attrib_type at 
         WHERE cs.seq_region_id=a.seq_region_id 
         AND   a.attrib_type_id=at.attrib_type_id 
         AND   at.code="toplevel";


4.2- dNdS Configuration
     ----------

In case you want to run the dN/dS part, you will also need this:

  { TYPE => dNdS,
    'codeml_parameters' 
      => do($ENV{BASEDIR}.'/ensembl-compara/scripts/homology/codeml.ctl.hash'),
    'species_sets' => '[[3,22,25,31,32,33,34,35,38],[4,13]]',
    'method_link_type' => 'ENSEMBL_ORTHOLOGUES'
  },

Where the species sets define the pairs of species for which one wants
to run the dNdS. For example:

    'species_sets' => '[[a,b,c,d],[x,y]]',
    'method_link_type' => 'ENSEMBL_ORTHOLOGUES'

would do the dNdS for the species pairs: a+b, a+c, a+d, b+c, b+d and
c+d and also between x+y.

One example of the codeml parameters needed can be found in
ensembl-compara/scripts/homology/codeml.ctl.hash


4.3- Bio::EnsEMBL::Analysis::Config files 
     ----------

Copy and modify the Bio::EnsEMBL::Analysis::Config::General file
You may need to change the locations of BIN_DIR, DATA_DIR and LIB_DIR;

  $ cd $BASEDIR/ensembl-analysis/modules/Bio/EnsEMBL/Analysis/Config
  $ cp General.pm.example General.pm
  <editor> General.pm

Copy and modify the Bio::EnsEMBL::Analysis::Config::Blast file

  $ cd $BASEDIR/ensembl-analysis/modules/Bio/EnsEMBL/Analysis/Config
  $ cp Blast.pm.example Blast.pm
  <editor> Blast.pm


Set the blast envirnment; these environment variables cannot be set in
either ::Config::Blast or ::Config::General;

in tcsh:
  $ setenv PATH /usr/local/ensembl/bin:$PATH
  $ setenv BLASTMAT /usr/local/ensembl/data/blastmat:$BLASTMAT
  $ setenv BLASTFILTER /usr/local/ensembl/bin:$BLASTFILTER


5- Create the species tree file 
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A NCBI taxon_id phylogenetic tree file representing the species in the
compara DB is required for the njtree stage. The file must be in Nexus
(.nh) format. If you are running the pipeline for your own set of
species, you can generate such a tree with the script
ensembl-compara/scripts/tree/testTaxonTree.pl.

One example of the species_tree_file can be found in
ensembl-compara/scripts/pipeline/species_tree_njtree.taxon_id.nh

To have your list of NCBI taxon_ids, you can use "-query_ncbi_name"
like this:

$ set COMPARA_URL='mysql://ensro@ens-staging/ensembl_compara_46'
$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL -query_ncbi_name "Anopheles gambiae"

NJTREE can distinguish between species that are supposed to have all
the genes represented in the DB and "incomplete" species, that may
have only a part of the genes represented. For the latter, NJTREE
won't try to estimate gene losses given this info.

If you have a DB with say 3 completely sequenced species, Anopheles
gambiae, Aedes aegypti and Drosophila melanogaster, and 2 incomplete
species, Pediculus humanus and Culex pipiens, you can create the
species tree like this:

(a) Look for the NCBI taxon_ids:

$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL -query_ncbi_name "Anopheles gambiae"

$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL -query_ncbi_name "Aedes aegypti"

$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL -query_ncbi_name "Drosophila melanogaster"

$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL -query_ncbi_name "Culex pipiens"

$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL -query_ncbi_name "Pediculus humanus"

the first three then being "-extrataxon_sequenced 7165_7159_7227", 
and the last two being: "-extrataxon_incomplete 7175_121225"

(b) Then you call the script like this:

$ perl $BASEDIR/ensembl-compara/scripts/tree/testTaxonTree.pl \
  -url $COMPARA_URL \
  -create_species_tree -extrataxon_sequenced 7165_7159_7227 \
  -extrataxon_incomplete 7175_121225  -no_previous

Which in this case will create your file with the name
"njtree.5.ensembl_compara_45.nh":

((((7175,7159*)53550,7165*)7157,7227*)7147,121225);

Also, there is an option to ignore internal nodes present in the NCBI
taxonomy. This will multifurcate the tree at the point when the given
node would disappear. For example, if one wants to ignore the
Coelomata (33316) internal node, and create a multifurcation at that
point, the option would be "-multifurcation_deletes_node 33316".

If you want to create a species_tree with all the species already
present in a previous Compara DB plus a few new species, you can use
the script connecting to that given DB and without the "-no_previous"
option. For example:

$ testTaxonTree.pl -url $COMPARA_URL \
  -create_species_tree -extrataxon_sequenced 9823 \
  -multifurcation_deletes_node 33316

will create a tree with the species in ensembl_compara_45, deleting
the Coelomata internal node and adding the Sus scrofa species as
completely sequenced.


6- Run the configure scripts
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The comparaLoadGenomes script use the information in the conf file to
connect to the core databases, queries for things like taxon_id,
assembly, gene_build, and names to create entries in the genome_db
table.  It also sets the genome_db.locator column to allow the system
to know where the respective core databases are located.  There is an
additional table called genome_db_extn which will be deprecated
shortly, but as of today (11 April, 2007) it is still used to hold a
'phylum' value for each genome to allow the option of building
homologies only within phylums.  This script will also 'seed' the
pipeline/hive system by creating the first jobs in the analysis_job
table for the analysis 'SubmitGenome'. Note that the
coord_system.version fields in the source species databases must be
set to a 'true' value for the script to work.

The loadGeneTreeSystem script creates the analysis entries for the
processing system, and creates both the dataflow rule and the analysis
control rules.  It also initializes the analysis_stats row for each
analysis.  These rows hold information like batch_size, hive_capacity,
and run-time stats that the Hive's Queen will update.

These scripts may give you warnings if the output directories are not
available or if it's unable to connect to core databases.

 $ cd $BASEDIR/ensembl-compara/scripts/pipeline
 $ ./comparaLoadGenomes.pl -conf my_compara.conf
 $ ./loadGeneTreeSystem.pl -conf my_compara.conf

If comparaLoadGenomes.pl or loadGeneTreeSystem.pl goes wrong, the DB
can be reset as follows (you need to re-run both);

 $ mysql $COMPARA_DBNAME \
   -e"delete from analysis;" -e"delete from analysis_ctrl_rule;" \
   -e"delete from analysis_data;" -e"delete from analysis_description;" \
   -e"delete from analysis_job;" -e"delete from analysis_stats;" \
   -e"delete from dataflow_rule;" \
   -e"delete from genome_db;" -e"delete from genome_db_extn;" \
   -e"delete from hive;" -e"delete from monitor;"

  $ mysql $COMPARA_DBNAME -e"show tables like 'peptide_align_feature_%'"
  (drop each of these)

7- Create the method_link_species_sets
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If you are running this for the Ensembl production release, make sure
that the method_link, species_set and method_link_species_set tables
in your compara DB are in sycn with the method_link_species_set in the
compara master db.
TODO: How to do this?

If not, create the method_link_species_sets that you need with the
create_mlss.pl script as follows;

7.1. First you will need an ensembl registry file that configures the
   database connection to the compara database. An example registry
   file would be;

  ---
  use Bio::EnsEMBL::Utils::ConfigRegistry;
  use Bio::EnsEMBL::DBSQL::DBAdaptor;
  use Bio::EnsEMBL::Compara::DBSQL::DBAdaptor;
  new Bio::EnsEMBL::Compara::DBSQL::DBAdaptor(
      -host    => 'localhost',
      -user    => 'admin',
      -pass    => 'secret',
      -port    => 3306,
      -species => 'compara-master',
      -dbname  => 'my_ensembl_compara_45');
  1;
  ---

7.2. You may need to create the following method_link entries;
  
  $ mysql $COMPARA_DBNAME -e \
    'INSERT INTO method_link (type, class) \
     VALUES ("ENSEMBL_ORTHOLOGUES","Homology.homology"), \
            ("ENSEMBL_PARALOGUES", "Homology.homology"), \
            ("PROTEIN_TREES",      "ProteinTree.protein_tree_node")'


7.3. Run the create_mlss.pl script. If, for example, your genome_db_ids
   were 1, 2, 3, 4 and 5, you would need the following;

  $ cd $BASEDIR/ensembl-compara/scripts/pipeline

  $ # For orthologues
  $ ./create_mlss.pl --f --pw \
    --reg_conf ensembl.registry \
    --method_link_type ENSEMBL_ORTHOLOGUES \
    --genome_db_id '1,2,3,4,5'

  $ # For between-species paralogues
  $ ./create_mlss.pl --f --pw \
    --reg_conf ensembl.registry \
    --method_link_type ENSEMBL_PARALOGUES \
    --genome_db_id '1,2,3,4,5'

  $ # For same-species paralogues
  $ ./create_mlss.pl --f --sg \
    --reg_conf ensembl.registry \
    --method_link_type ENSEMBL_PARALOGUES \
    --genome_db_id '1,2,3,4,5'

  $ # For protein trees
  $ ./create_mlss.pl --f \
    --reg_conf ensembl.registry \
    --method_link_type PROTEIN_TREES \
    --genome_db_id '1,2,3,4,5'

At this point the system is ready to run..


8- Run the hive
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

One must first make sure that the available hive scripts are available
in one's path.  This can be done by either extending PATH or linking the
scripts to an existing directory in the PATH

  tcsh$ setenv PATH ${PATH}:${BASEDIR}/ensembl-hive/scripts
  bash$ export PATH=$PATH:$BASEDIR/ensembl-hive/scripts

You may also need to set the LSB_DEFAULTPROJECT environment variable
if you are using LSF across the sanger farm;

  tcsh$ setenv LSB_DEFAULTPROJECT ensembl-compara
  bash$ export LSB_DEFAULTPROJECT=ensembl-compara
       
There are two beekepers, one which uses LSF job submission system, and
another that uses the local machine only. If using the local machine,
add the -local flag to the command and the workers will run as 
background system commands rather than being submited to an LSF resource.

 $ beekeeper.pl \
   -url $COMPARA_URL -loop

where 'user' and 'password' allow write access to the database

Running the complete build for ensembl45 with 35 species on the Sanger
CPU cluster takes (depending on availability of resources):

- from 1-3 days for the blasts
- half a day for the clustering
- 2-3 days for the multialignments, trees and homologies

If you want to manually run one of the jobs in the pipeline in
debugging mode to see if everything is working as expected, query the
db for your analysis_job_id and use the runWorker.pl script like this:

mysql -hcompara2 -uensro avilella_compara_homology_small_45 -e \
 "select * from analysis_job aj, analysis a where \
 a.analysis_id=aj.analysis_id and a.logic_name='Muscle' limit 10"

# This will print the first 10 Muscle jobs, then get the
analysis_job_id for one of them and run:

perl ensembl-hive/scripts/runWorker.pl -bk LOCAL \
 -url mysql://ensadmin:ensembl@compara2/avilella_compara_homology_small_45 \
 -outdir '' -no_cleanup -debug 1 --job_id 1234567

for more details on controling the hive system do
  $ beekeeper.pl -help
