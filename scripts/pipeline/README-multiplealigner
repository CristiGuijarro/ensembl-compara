

1- code API needed and executable
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  bioperl-live (bioperl-1-2-0?)
  ensembl
  ensembl-compara
  ensembl-hive
  ensembl-pipeline
  ensembl-analysis

  executables
  ~~~~~~~~~~~
  mercator
      using /usr/local/ensembl/bin/mercator
  blastz
      using /usr/local/ensembl/bin/blastz

1.2 Code checkout

      cvs -d :ext:bio.perl.org:/home/repository/bioperl co -r branch-07 bioperl-live
      cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co ensembl
      cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co  ensembl-pipeline
      cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co  ensembl-hive
      cvs -d :ext:cvs.sanger.ac.uk:/nfs/ensembl/cvsroot co  ensembl-analysis

in tcsh
    setenv BASEDIR   /some/path/to/modules
    setenv PERL5LIB  ${BASEDIR}/ensembl/modules:${BASEDIR}/ensembl-pipeline/modules:${BASEDIR}/bioperl-live:${BASEDIR}/ensembl-compara:${BASEDIR}/ensembl-hive:${BASEDIR}/ensembl-analysis
    setenv PATH $PATH:${BASEDIR}/ensembl-compara/script/pipeline:${BASEDIR}/ensembl-hive/scripts

in bash
    BASEDIR=/some/path/to/modules
    PERL5LIB=${BASEDIR}/ensembl/modules:${BASEDIR}/ensembl-pipeline/modules:${BASEDIR}/bioperl-live:${BASEDIR}/ensembl-compara:${BASEDIR}/ensembl-hive:${BASEDIR}/ensembl-hive
    PATH=$PATH:${BASEDIR}/ensembl-compara/scripts/pipeline:${BASEDIR}/ensembl-hive/scripts

1.3 Configure the Pipeline:

  Copy ${BASEDIR}/ensembl-pipeline/modules/Bio/EnsEMBL/Pipeline/Config/Blast.pm.example to ${BASEDIR}/ensembl-pipeline/modules/Bio/EnsEMBL/Pipeline/Config/Blast.pm


2- Create a hive/compara database
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Pick a mysql instance and create a database

mysql -h ia64g -P3306 -uensadmin -pxxxx -e "create database abel_compara_mlagan"

cd ~/src/ensembl_main/ensembl-hive/sql
mysql -h ia64g -P3306 -uensadmin -pxxxx abel_compara_mlagan < tables.sql

cd ~/src/ensembl_main/ensembl-compara/sql
mysql -h ia64g -P3306 -uensadmin -pxxxx abel_compara_mlagan < table.sql
mysql -h ia64g -P3306 -uensadmin -pxxxx abel_compara_mlagan < pipeline-tables.sql

Add an entry in your registry configuration file:

new Bio::EnsEMBL::Compara::DBSQL::DBAdaptor(
    -host => 'ia64g',
    -user => 'ensadmin',
    -pass => 'XXXXXXXX',
    -port => 3306,
    -species => 'abel_compara_mlagan',
    -dbname => 'abel_compara_mlagan');

Populate the database with data from the master DB:

~/src/ensembl_main/ensembl-compara/scripts/pipeline/populate_new_database.pl \
  --master compara-master --new abel_compara_mlagan

3- Choose a working directory with some disk space
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The multiple aligner pipeline tries to minize the amount of output data for workers. But if 
debug options is on this can take some space. So be careful.

mkdir -p /acari/work7a/abel/hive/abel_compara_mlagan/workers
mkdir -p /acari/work7a/abel/hive/abel_compara_mlagan/blastDB

This directory needs to be set in 'hive_output_dir' variable in the compara-hive
configuration file. See below. If not set, all STDOUT/STDERR goes to /dev/null. :)

4- Copy and modify your compara-hive config file
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

cd /acari/work7a/abel/hive/abel_compara_mlagan

cp ~/src/ensembl_main/ensembl-compara/scripts/pipeline/compara-hive-mulitplealigner.conf.example hive.conf.pl
cp ~/src/ensembl_main/ensembl-compara/scripts/pipeline/hmr.tree.example hmr.tree
<editor> hive.conf.pl
<editor> hmr.tree

you may need to change the database names, port, dbnames, and the
paths to the 'hive_output_dir' to
/acari/work7a/abel/hive/abel_compara_mlagan/workers
'fasta_dir' and 'tree_file' will need to be updated as well.
The species names should correspond to the genome_db_id of the species used (and defined in the 
hive configuration file).

You can have several multiple alignment pipelines working in the same HIVE. To do this, add an extra
MULTIPLE_ALIGNER block in the configuration file and change the corresponding list of species and the
tree file. The HIVE will run the all-vs-all balstp jobs and then build a Synteny map for each
multiple alignment pipeline. The resulting syntenies will be used to feed the multiple aligner.

You can also have a CONSERVATION_SCORE block if you want to run Gerp or any other similar software
to get constrained elements and conservation scores from the resulting multiple alignments.

To run Gerp you will also need to create a parameter file, for example:

-----------------------------------
alignment	gerp_alignment.mfa
phylo_tree	gerp_tree.nw
window_length	1
repeats		NULL
no_rsmin_estimate
merge_distance	6
rej_sub_min     8.5
no_ABC_files
-----------------------------------

where alignment: alignment file used in multi-fasta format
      phylo_tree: tree file
      window_length: length of window used for sliding window rate estimation
      repeats: either the repeat annonation file or NULL to ignore repeats
      no_rsmin_estimate: no automatic estimation of restricted substitution rate
      merge_distance: maximum number of unconstrained scores allowed between candiate constrained elements
      rej_sub_min: threshold score to define candidate constrained element as significant
      no_ABC_files: no ABC files produced

For the SYNTENY_MAP_BUILDER, the MULTIPLE_ALIGNER and the CONSERVATION_SCORE blocks you can specify
the logic_name for the method. You can also specify the module name. If none is given, the hive will
use the Bio::EnsEMBL::Compara::Production::GenomicAlignBlock::$logic_name module.

5- Run the configure scripts
   ~~~~~~~~~~~~~~~~~~~~~~~~~
The following scripts are in ensembl-compara/scripts/pipeline (should be in your PATH)
The order of execution is important

comparaLoadGenomes.pl -conf hive.conf.pl
loadMultipleAlignerSystem.pl -conf hive.conf.pl

The comparaLoadGenomes script use the information in the conf file to connect to
the core databases, queries for things like taxon_id, assembly, gene_build, and names
to create entries in the genome_db table.  It also sets the genome_db.locator column to
allow the system to know where the respective core databases are located. This script 
will also 'seed' the pipeline/hive system by creating the first jobs in the analysis_job
table for the analysis 'SubmitGenome'.

The loadMultipleAlingerSystem script creates the analysis entries for the processing
system, and creates both the dataflow rule and the analysis control rules.
It also initializes the analysis_stats row for each analysis.  These row hold
information like batch_size, hive_capacity, and run-time stats that the Hive's
Queen will update.

These scripts may give you warnings if the output directories are not available or if
it's unable to connect to core databases.

At this point the system is ready to run

NB: Although this feature has not been extensivelly tested, it should be
  possible to start the pipeline with all but one species if this one is not
  ready yet. You will need to update manually the analysis_job table and set
  the status of the relevant analysis_job (<analysis_id> = 1 for SubmitGenome
  analysis and <input_id> should match the genome_db_id of the species you
  want to block) to "BLOCKED". Later on, you can set the status back to "READY"
  in order to unblock it.


6- Run the beekeeper
   ~~~~~~~~~~~~~~~~~

Run it on i386 (32-bits) machines (The mercator part works only on these machines).

The following scripts are in ensembl-hive/scripts (should be in your PATH)
beekeeper.pl -lsf_options "-R\"type==LINUX86\"" -url mysql://ensadmin:xxxx@ia64g:3306/abel_compara_mlagan -loop

where xxxx is the password for write access to the database

for more details on controling/monitoring the hive system see 
beekeeper -help

Some MLAGAN jobs might fail because of memory requirements. You can find these jobs using the following commend:
$> beekeeper.pl --url mysql://ensadmin:xxxx@ia64g:3306/abel_compara_mlagan --failed_jobs

Then you can reset these jobs with:
$> beekeeper.pl --url mysql://ensadmin:xxxx@ia64g:3306/abel_compara_mlagan --reset_job_id 42483

And finally rerun them using the hugemem queue:
$> beekeeper.pl --lsf_options '-R "select[mem>=4000] rusage[mem=4000]" -q hugemem' --url mysql://ensadmin:xxxx@ia64g:3306/abel_compara_mlagan --loop
